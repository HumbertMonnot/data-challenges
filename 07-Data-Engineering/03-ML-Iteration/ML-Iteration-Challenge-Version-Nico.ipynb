{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3 - ML Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have already built a simple, we want to make it better! The ultimate goal is having a model that makes more accurate predictions on the test set, hence getting a RMSE as low as possible.\n",
    "\n",
    "**So what can we do?**\n",
    "\n",
    "There are many different things that make models better:\n",
    "- build and try to use different or more features\n",
    "- test with different estimators (linear, non linear, etc..)\n",
    "- tune hyperparameters\n",
    "\n",
    "\n",
    "The problem is that it is often hard to keep track of this different experimentations. There are many different parameters that we can tune and many different combinations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[MLFlow](https://www.mlflow.org/docs/latest/concepts.html) is a very useful tool to help us in machine learning models iteration.** \n",
    "\n",
    "In this series of exercise, you will get hands on using the [MLFlow Tracking Api](https://www.mlflow.org/docs/latest/tracking.html) in order to experiment with different features, models and parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "0. [Workflow setup](#part0)\n",
    "1. [Setup MLflow Tracking](#part1)\n",
    "2. [Try different models](#part2)\n",
    "3. [Features engineering](#part3)\n",
    "4. [Hyperparameters tuning](#part4)\n",
    "5. [MLFlow Projects](#part5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Workflow Setup <a id=\"part0\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to move away from Jupyter Notebook, and start writing reusable code with python modules and classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create our folder structure:\n",
    "\n",
    "1. Create a folder with the name of your project/module, for example `TaxiFareModel`\n",
    "2. Inside this folder, create a `__init_.py` file to make it a python module\n",
    "3. Then create multiple python files that will contain the different python classes or methods we need\n",
    "\n",
    "\n",
    "* `trainer.py`: **Trainer** class that will be our main class that trains our model\n",
    "* `data.py`: **Data** class that will be responsible for getting the input raw data\n",
    "* `utils.py`: any utility functions you may have\n",
    "* `encoders.py`: your custom encoders and transformers\n",
    "\n",
    "You should have something like:\n",
    "\n",
    "* TaxiFareModel\n",
    "    * __init__.py\n",
    "    * trainer.py\n",
    "    * data.py\n",
    "    * utils.py\n",
    "    * encoders.py\n",
    "    * data\n",
    "      * train.csv\n",
    "      * test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data.py\n",
    "- Create the `Data` class. This class should have a method `get_data` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    \n",
    "    def get_data(self, nrows=None, test=False):\n",
    "        \"\"\"returns the input data\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello john, my name is mike'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/997797/what-does-s-mean-in-a-python-format-string\n",
    "\n",
    "import os\n",
    "\"Hello %s, my name is %s\" % ('john', 'mike')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utils.py\n",
    "- In `utils.py` this where you can have :\n",
    " - `haversine_distance` method\n",
    " - `compute_rmse` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### encoders.py\n",
    "- In `encoders.py` let's put the custom encoders and transformers you have for distance and time features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trainer.py\n",
    "- The `Trainer` class is the main class. It should have:\n",
    "  - a `def get_estimator()` to return the estimator chosent to train the model\n",
    "  - a `def get_pipeline()` method that builds the pipeline\n",
    "  - a `def fit()` method that train the pipeline\n",
    "  \n",
    "  \n",
    "- You can also have a `train` method that:\n",
    " - gets the training data\n",
    " - split date into train/validation sets\n",
    " - fits a model on that training data\n",
    " - evaludate the model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, RidgeCV, LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import svm\n",
    "\n",
    "class Trainer(object):\n",
    "    \n",
    "    EXPERIMENT_NAME = \"MyExperiment\"\n",
    "    TRAINING_NROWS = 10000\n",
    "    ESTIMATOR = \"Lasso\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.pipeline = None\n",
    "        self.kwargs = kwargs\n",
    "        self.experiment_name = kwargs.get(\"experiment_name\", self.EXPERIMENT_NAME)\n",
    "        self.nrows = kwargs.get(\"nrows\", self.TRAINING_NROWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(trainer.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MyExperiment'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "\n",
    "    EXPERIMENT_NAME = \"MyExperiment\"\n",
    "    TRAINING_NROWS = 10000\n",
    "    ESTIMATOR = \"Lasso\"\n",
    "\n",
    "# See the jupyter notebook\n",
    "# This gives a default value to get() for keys that are not in the dictionnary\n",
    "# https: // stackoverflow.com / questions / 1098549 / proper - way - to - use - kwargs - in -python\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.pipeline = None\n",
    "        self.kwargs = kwargs\n",
    "        self.experiment_name = kwargs.get(\"experiment_name\", self.EXPERIMENT_NAME)\n",
    "        self.nrows = kwargs.get(\"nrows\", self.TRAINING_NROWS)\n",
    "\n",
    "    def get_estimator(self):\n",
    "        estimator = self.kwargs.get(\"estimator\", self.ESTIMATOR)\n",
    "        if estimator == \"Lasso\":\n",
    "            estimator = LassoCV(cv=5, n_alphas=5)\n",
    "        elif estimator == \"Ridge\":\n",
    "            estimator = RidgeCV(cv=5)\n",
    "        elif estimator == \"Linear\":\n",
    "            estimator = LinearRegression()\n",
    "        elif estimator == \"GBM\":\n",
    "            estimator = GradientBoostingRegressor()\n",
    "        else:\n",
    "            estimator = LassoCV(cv=5, n_alphas=5)\n",
    "        estimator_params = self.kwargs.get(\"estimator_params\", {})\n",
    "        estimator.set_params(**estimator_params)\n",
    "        return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=None, copy_X=True, cv=5, eps=0.001, fit_intercept=True,\n",
       "        max_iter=1000, n_alphas=5, n_jobs=None, normalize=False, positive=False,\n",
       "        precompute='auto', random_state=None, selection='cyclic', tol=0.0001,\n",
       "        verbose=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_estimator = new_trainer.get_estimator()\n",
    "new_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#if you want to know current working dir\n",
    "os.getcwd()\n",
    "#if you want to change\n",
    "os.chdir('/Users/nicolasbancel/git')\n",
    "# if you want to list dir\n",
    "#os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxifaremodel.data import Data\n",
    "from taxifaremodel.encoders import TimeFeaturesEncoder, DistanceTransformer\n",
    "from taxifaremodel.utils import compute_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it!\n",
    "- Once you have everything setup, test that it works by calling `Trainer.train()` from your notebook.\n",
    "- Do not hesitate to only breakdown your code into smaller calls for debugging\n",
    "- Tip\n",
    "  - add `%load_ext autoreload` and `%autoreload 2` in your notebook to automaticall have new code imported anytime you make a change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from TaxiFareModel.trainer import Trainer\n",
    "# t = Trainer()\n",
    "# t.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup MLFlow Tracking <a id=\"part1\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since that now we have a good workflow to make model improvements, it is very important to track all our different experiments. We want to be able to save all our differents training runs and compare their performance.\n",
    "\n",
    "This is what MLFlow tracking is about.\n",
    "\n",
    "#### Exercise\n",
    "- Read [MLFlow Quickstart](https://www.mlflow.org/docs/latest/quickstart.html#quickstart)\n",
    "- Install MLFlow with `pip install mlflow`\n",
    "- Setup MLFlow in your code to start logging training runs\n",
    " - Think about which parameters you want to log\n",
    " - Think about the metric you want to log\n",
    "- Re-organize your code in order to easily log the different parameters and metrics you need\n",
    "    - Extract out the different parameters you may have in your code and make them inputs of your `Trainer(object)` class.\n",
    "    - **Tips**:\n",
    "       - If you want to log the estimator used, you can do it with `estimator.__class__.__name__`\n",
    "       - Look at the estimator documentation to extract the params programmatically \n",
    "    - Write a method `log_mlflow_params` to automatically log the params\n",
    "- View results with `mlflow ui`\n",
    "\n",
    "To go further, look at the [full doc](https://www.mlflow.org/docs/latest/tracking.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def get_estimator(self):\n",
    "        \"\"\"use kwargs to set your estimator and params \"\"\"\n",
    "        \n",
    "    def log_mlflow_params(self, **kwargs):\n",
    "        \"\"\"log params to mlflow here\"\"\"\n",
    "        \n",
    "    def log_mlflow_metric(self, **kwargs):\n",
    "        \"\"\"log metric to mlflow here\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import mlflow\n",
    "from  mlflow.tracking import MlflowClient\n",
    "from memoized_property import memoized_property\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "\n",
    "    EXPERIMENT_NAME = \"MyExperiment\"\n",
    "    TRAINING_NROWS = 10000\n",
    "    ESTIMATOR = \"Lasso\"\n",
    "\n",
    "# See the jupyter notebook\n",
    "# This gives a default value to get() for keys that are not in the dictionnary\n",
    "# https: // stackoverflow.com / questions / 1098549 / proper - way - to - use - kwargs - in -python\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.pipeline = None\n",
    "        self.kwargs = kwargs\n",
    "        self.experiment_name = kwargs.get(\"experiment_name\", self.EXPERIMENT_NAME)\n",
    "        self.nrows = kwargs.get(\"nrows\", self.TRAINING_NROWS)\n",
    "\n",
    "    def get_estimator(self):\n",
    "        estimator = self.kwargs.get(\"estimator\", self.ESTIMATOR)\n",
    "        if estimator == \"Lasso\":\n",
    "            estimator = LassoCV(cv=5, n_alphas=5)\n",
    "        elif estimator == \"Ridge\":\n",
    "            estimator = RidgeCV(cv=5)\n",
    "        elif estimator == \"Linear\":\n",
    "            estimator = LinearRegression()\n",
    "        elif estimator == \"GBM\":\n",
    "            estimator = GradientBoostingRegressor()\n",
    "        else:\n",
    "            estimator = LassoCV(cv=5, n_alphas=5)\n",
    "        estimator_params = self.kwargs.get(\"estimator_params\", {})\n",
    "        estimator.set_params(**estimator_params)\n",
    "        return estimator\n",
    "\n",
    "    def get_pipeline(self):\n",
    "        distance_transformer = DistanceTransformer(\n",
    "            start_lat=\"pickup_latitude\", start_lon=\"pickup_longitude\",\n",
    "            end_lat=\"dropoff_latitude\", end_lon=\"dropoff_longitude\",\n",
    "        )\n",
    "        features_encoder = ColumnTransformer([\n",
    "            ('time_features', make_pipeline(TimeFeaturesEncoder(time_column='pickup_datetime'), OneHotEncoder()),['pickup_datetime']),\n",
    "            ('distance', make_pipeline(distance_transformer, SimpleImputer()),['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']),\n",
    "            ('passenger_count', SimpleImputer(), ['passenger_count'])\n",
    "        ])\n",
    "        return Pipeline(\n",
    "            steps=[\n",
    "                ('features', features_encoder),\n",
    "                ('clf', self.get_estimator())\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def fit(self, df_train):\n",
    "        pipeline = self.get_pipeline()\n",
    "        pipeline.fit(df_train, df_train.fare_amount)\n",
    "        self.pipeline = pipeline\n",
    "\n",
    "    def evaluate(self, df_test):\n",
    "        if self.pipeline is None:\n",
    "            raise (\"Cannot evaluate an empty pipeline\")\n",
    "        y_pred = self.pipeline.predict(df_test)\n",
    "        return compute_rmse(y_pred, df_test.fare_amount)\n",
    "    \n",
    "    def log_estimator_params(self):\n",
    "        clf = self.get_estimator()\n",
    "        self.mlflow_log_param('estimator_name', clf.__class__.__name__)\n",
    "        params = clf.get_params()\n",
    "        for k, v in params.items():\n",
    "            pass\n",
    "          #self.mlflow_log_param(k, v)\n",
    "\n",
    "  ### MLFlow methods\n",
    "    @memoized_property\n",
    "    def mlflow_run(self):\n",
    "        return self.mlflow_client.create_run(self.mlflow_experiment_id)\n",
    "\n",
    "    @memoized_property\n",
    "    def mlflow_experiment_id(self):\n",
    "        try:\n",
    "            return self.mlflow_client.create_experiment(self.experiment_name)\n",
    "        except BaseException:\n",
    "            return self.mlflow_client.get_experiment_by_name(self.experiment_name).experiment_id\n",
    "\n",
    "    @memoized_property\n",
    "    def mlflow_client(self):\n",
    "        return MlflowClient()\n",
    "\n",
    "    def mlflow_log_param(self, key, value):\n",
    "        self.mlflow_client.log_param(self.mlflow_run.info.run_id, key, value)\n",
    "        \n",
    "    def mlflow_log_metric(self, key, value):\n",
    "        self.mlflow_client.log_metric(self.mlflow_run.info.run_id, key, value)\n",
    "\n",
    "    def train(self):\n",
    "        df = Data().get_data(nrows=100000)\n",
    "        df_train, df_val = train_test_split(df, random_state=99, test_size=0.05)\n",
    "        df_train = df_train.sample(n=self.nrows)\n",
    "        self.fit(df_train)\n",
    "\n",
    "        self.log_estimator_params()\n",
    "        self.mlflow_log_param(\"nrows\", self.nrows)\n",
    "\n",
    "        rmse = self.evaluate(df_val)\n",
    "        self.mlflow_log_metric(\"rmse\", rmse)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     for n in np.arange(500, 50000, 100):\n",
    "#         t = Trainer(experiment_name='training_size_experiment', nrows=n)\n",
    "#         t.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"estimator\": \"Lasso\", \"estimator_params\": {\"cv\": 5}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-073e47579584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "root = os.path.dirname(os.path.realpath(__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nicolasbancel/git'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Trainer(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to make sure data.csv and test.csv are in the folder\n",
    "df = Data().get_data(nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Won't work because some expensive load doesn't do anything\n",
    "\n",
    "class class_example(object):\n",
    "    @property\n",
    "    def name(self):\n",
    "        if not hasattr(self, '_name'):\n",
    "            self._name = some_expensive_load()\n",
    "        return self._name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memoized_property import memoized_property\n",
    "\n",
    "class class_example_two(object):\n",
    "\n",
    "    @memoized_property\n",
    "    def name(self):\n",
    "        # Boilerplate guard conditional avoided, but this is still only called once\n",
    "        return some_expensive_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = class_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organize your runs into MLflow Experiments\n",
    "In order to have your runs organized, you can leverage [MLFlow experiments](https://www.mlflow.org/docs/latest/tracking.html#organizing-runs-in-experiments).\n",
    "\n",
    "For this, it is easier to use the MLFlow API with [`MlflowClient`](https://www.mlflow.org/docs/latest/python_api/mlflow.tracking.html#module-mlflow.tracking)\n",
    "\n",
    "#### Exercise\n",
    "- Write a few additional methods to manage the creation of experiments and runs in your class.\n",
    "- Also write wrappers around `log_metric` and `log_param` MLflow methods to easily log based on your current experiment and run\n",
    "- @memoized_property is a useful decorator to declare properties see [https://pypi.org/project/memoized-property/](https://pypi.org/project/memoized-property/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memoized_property\n",
    "def mlflow_run(self):\n",
    "    return self.mlflow_client.create_run(self.mlflow_experiment_id)\n",
    "\n",
    "@memoized_property\n",
    "def mlflow_experiment_id(self):\n",
    "    try:\n",
    "        return self.mlflow_client.create_experiment(self.experiment_name)\n",
    "    except BaseException:\n",
    "        return self.mlflow_client.get_experiment_by_name(self.experiment_name).experiment_id\n",
    "\n",
    "@memoized_property\n",
    "def mlflow_client(self):\n",
    "    return MlflowClient()\n",
    "\n",
    "def mlflow_log_param(self, key, value):\n",
    "    self.mlflow_client.log_param(self.mlflow_run.info.run_id, key, value)\n",
    "    \n",
    "def mlflow_log_metric(self, key, value):\n",
    "    self.mlflow_client.log_metric(self.mlflow_run.info.run_id, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxifaremodel.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Trainer(experiment_name='Experiment0')\n",
    "t.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write a loop that will launch multiple runs for different parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TaxiFareModel.trainer import Trainer\n",
    "for param in ['param1', 'param2', 'param3']:\n",
    "    t = Trainer(experiment_name='Experiment1', param=param)\n",
    "    t.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of taxifaremodel.trainer failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/nicolasbancel/git/taxifaremodel/trainer.py\", line 23, in <module>\n",
      "    class Trainer(object):\n",
      "  File \"/Users/nicolasbancel/git/taxifaremodel/trainer.py\", line 88, in Trainer\n",
      "    herjkhz\n",
      "NameError: name 'herjkhz' is not defined\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from taxifaremodel.trainer import Trainer\n",
    "#for n in np.arange(500, 50000, 100):\n",
    "for n in np.arange(500, 50000, 100)[0:20]:\n",
    "    t = Trainer(experiment_name='training_size_experiment', nrows=n)\n",
    "    t.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then go to MLFlow UI to see the different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 500,  600,  700,  800,  900, 1000, 1100, 1200, 1300, 1400, 1500,\n",
       "       1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starts at 500, ends at 50000, by increment of 100\n",
    "np.arange(500, 50000, 100)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Try different models <a id=\"part2\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a way to track different iterations, it is time to experiment!\n",
    "\n",
    "**First, let's try different estimators.**\n",
    "\n",
    "#### Exercise\n",
    "- Think about the different estimators that you know that can be used to solve prediction problems\n",
    "- Implement a short script that will loop through all estimators, train the model and evalulate it on a validation set.\n",
    "- Be careful: make sure you always use the same validation set accross all your trainings. **Tip** you can set the random seed for `train_test_split` to make sure the split is always the same.\n",
    "- Compare performance with `mlflow ui`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## experiment for nrows\n",
    "import numpy as np\n",
    "from TaxiFareModel.trainer import Trainer\n",
    "for estimator in [\"Lasso\", \"Ridge\", \"Linear\", \"GBM\"]:\n",
    "    print(estimator)\n",
    "    t = Trainer(experiment_name='estimators_experiment', estimator=estimator)\n",
    "    t.train()\n",
    "Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Features engineering and selection <a id=\"part3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now it is time to be creative!**\n",
    "\n",
    "You just tried different models, and you now see that some estimators may be more powerful than others. Another area where you can experiment is about `features engineering`. \n",
    "\n",
    "#### Exercise 1\n",
    "- Try different combinations of features (by removing or adding some) and track the runs.\n",
    "- Use [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) transfomer to generate new features from distance.\n",
    "- Compute other types of distance (straightline, manhattan, travel, etc..)\n",
    "- Use some \"context knowledge\" to generate new features that you think might be relevant.\n",
    " - For example: we know that taxis apply a fixed fare for airport transfers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 2\n",
    "- Try different methods for outliers removals\n",
    "- Look at how the size of the training set helps reduce the RMSE on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hyperparameters tuning <a id=\"part4\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, once you are satisfied with your features engineering work, **let's fine tune your model.**\n",
    "\n",
    "For this, we recommand you choosing a `Gradient Boosting Tree` estimator ([Xgboost](https://xgboost.readthedocs.io/en/latest/get_started.html) or [LightGBM](https://lightgbm.readthedocs.io/en/latest/) or [GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)).\n",
    "\n",
    "The idea is to tune the hyperparameters of this estimator. The most important parameters to tune are:\n",
    "- `learning_rate`\n",
    "- `max_depth`\n",
    "- `n_estimators`\n",
    "\n",
    "To perform hyperparameters search, you have the choice between two `search` mechanisms:\n",
    "- [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "- [RandomSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "\n",
    "\n",
    "#### Exercise\n",
    "- First, try to adjust the hyperparameters manually and do a few runs that you can track with MLFlow. Then [with MLFlow UI you can visually see how these parameters affect the performance metric](https://mlflow.org/docs/latest/tracking.html#visualizing-metrics).\n",
    "- Once you have an idea of how the parameters impact RMSE, try to implement both `GridSearch` and `RandomSearch` as part of your pipeline to fully tune the model.\n",
    "- Once you are satisfied with your tuned model, submit your predictions to Kaggle!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. MLFlow projects <a id=\"part5\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To go further, look at [MLFlow Projects](https://www.mlflow.org/docs/latest/projects.html#) and see how you can use them to perform hyperparameters tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
