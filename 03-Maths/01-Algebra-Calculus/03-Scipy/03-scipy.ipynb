{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize with SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say hello to [SciPy](https://www.scipy.org/), a powerful library used for mathematics in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous exercice, we saw the importance of finding the minimum of a given function - for instance, `RMSE = f(intercept_coef, slope_coef)`, and the two main approaches possible: iterative approaches (such as gradient descent) and closed-formed (such as matrix inversion).\n",
    "\n",
    "Let's use the [`scipy.optimize`](https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html) library to do that in a few line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 1D-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose a given function f\n",
    "def f(x):\n",
    "    return (x**2 - 20 * np.cos(x))\n",
    "\n",
    "# Plot it below between -10 and +10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the local minimum of f, from a starting point xO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Notice the minimum found in variable `x`, and the number of iterations it took to converge: `nint`. What can you conclude? Try to change the `x0`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üëâ Explanations</summary>\n",
    "After <code>nint</code> iterations with gradient-descent, the algorithm of the <code>minimize()</code> function gets stuck on a local minimum <code>x</code>, except if it starts from values of <code>x0</code> close enough to the global minimum (0). The value of the local minimum found is <code>fun</code>\n",
    "    \n",
    "In math, we say that this function is not [convex](https://en.wikipedia.org/wiki/Convex_function). If it were convex, any minimum would be the global minimum! In fact, machine-learning loves convexity, and such problems are very easy to solve with iterative processes such as gradient descent.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 2D-function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in previous exercice, finding the minimum of a function with more than one parameter becomes rapidly complex. Let's try out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(X):\n",
    "    return np.sin(X[0]**2 + X[1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the local minimum of g, from a starting point X0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìIs this the absolute minimum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí°Hint</summary>\n",
    "Try this out to plot the function\n",
    "<pre>\n",
    "x = np.linspace(-5,5,100) # shape(100,1)\n",
    "y = np.linspace(-5,5,100) # shape(100,1)\n",
    "xx, yy = np.meshgrid(x,y) # x and y of shape(100,100)\n",
    "zz = np.array([xx,yy]) # shape(2, 100, 100)\n",
    "\n",
    "plt.contourf(xx,yy,g(zz), 40)\n",
    "plt.colorbar()\n",
    "plt.scatter(0, 0, c='r')\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Minimize under constraint üî•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a real world problem, we often want to minimize a function $f(\\textbf{x})$, **given a set of constraints on the values of $\\textbf{x}$ itself**.  \n",
    "\n",
    "\n",
    "For instance, let's say we want to minimize \n",
    "\n",
    "$f(\\textbf{x}) = x_1 x_4 (x_1 + x_2 + x_3) + x_3$  \n",
    "\n",
    "Given the following constraints\n",
    "\n",
    "\n",
    "$[1]\\ \\ x_1^2 + x_2^2 + x_3^2 + x_4^2 = 40$  (*equality constraint*)\n",
    "\n",
    "$[2]\\ \\ x_1 x_2 x_3 x_4 \\leqslant 25$ (*inequality constraint*)\n",
    "\n",
    "$[3]\\ \\ 1 \\leqslant x_1, x_2, x_3, x_4 \\leqslant 5$ (*bounds*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look easy? We will use the same `optimize.minimize` method with additional arguments as follows: \n",
    "\n",
    "`optimize.minimize(f, X0, constraints=cons, bounds=boundaries)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your objective function f(X) that you want to minimize, X being a ndarray "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build our constraints functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function constraint1(X) that returns 0 if and only if equation [1] is True\n",
    "def constraint1(X):\n",
    "    pass\n",
    "\n",
    "# Define a function constraint2(X) that returns a number that is always <= 0 if and only if equation [2] is True\n",
    "def constraint2(X):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now define the \"constraint\" argument needed for the minimize function. Pay attention to the scipy syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "con1 = {\"type\": \"eq\", \"fun\": constraint1}\n",
    "con2 = {\"type\": \"ineq\", \"fun\": constraint2}\n",
    "constraints = [con1, con2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's deal with equation [3].\n",
    "We could write them in the form of 10 constraints functions, but it would be long  \n",
    "Instead, scipy allows to create \"boundaries\" arguments for the variables we look for, in the following form:  \n",
    "`bounds` = tuple of tuple ((x1_min, x_1_max), (x2_min, x_2_max), ....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, define a starting point X0 for the minimization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Now, try to find the minimum of your objective function `f` under such constraints using `optimize.minimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Minimize under constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Easy? Not so fast. As illustrated previously, you found a **local** minimum to your objective function f, given a starting point $X0$. Nothing proves that this is a global minimum. \n",
    "\n",
    "‚ùì Can you think of a procedure that would increase your chance of finding the **global** minima?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí°Hints</summary>\n",
    "\n",
    "üëâ One empirical idea is to loop over lots of random starting points $X0$, and store the minimum value found at each run. After each iteration, you increase your chance of finding the global minimum (if there is any). Feel free to have a go\n",
    "\n",
    "üí™ A more robust idea is to try to prove mathematically that your optimization problem is geometrically [convex](https://en.wikipedia.org/wiki/Convex_function). An optimization problem is convex if (i) its objective function `f` is a convex function, (ii) the inequality constraints are convex, and (iii) the equality constraints are\n",
    "affine. Read in this excellent math-based presentation from Berkely: [Convex Optimization for Machine Learning](https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/optimization/slides.pdf)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your answer here in plain english text (no need to code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "üëç Congratulations for solving your first optimization under constraint problem.\n",
    "\n",
    "Often in Data Science, the hard part is not the computation itself, but the **problem statement** - i.e. turning a problem into equations.\n",
    "\n",
    "‚ùìAs an optional exercice, feel free to try to write down equations and solve the famous [Knapsack problem](https://en.wikipedia.org/wiki/Knapsack_problem): You are given a backpack that can carry at best 20kg, and a set of items (20 items) that each have a given value and weight (pick your own values). How could you maximise the total value of your backpack, given the constraint that the sum of all items does not exceed 20kg?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit a scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often have to fit a scatterplot with a straght line, but it can also happen to look like something else (polynomial, logarithmic etc...)\n",
    "\n",
    "Consider the dataset below: would you try to fit a linear regression curve to it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.array([-3.        , -2.87755102, -2.75510204, -2.63265306, -2.51020408,\n",
    "       -2.3877551 , -2.26530612, -2.14285714, -2.02040816, -1.89795918,\n",
    "       -1.7755102 , -1.65306122, -1.53061224, -1.40816327, -1.28571429,\n",
    "       -1.16326531, -1.04081633, -0.91836735, -0.79591837, -0.67346939,\n",
    "       -0.55102041, -0.42857143, -0.30612245, -0.18367347, -0.06122449,\n",
    "        0.06122449,  0.18367347,  0.30612245,  0.42857143,  0.55102041,\n",
    "        0.67346939,  0.79591837,  0.91836735,  1.04081633,  1.16326531,\n",
    "        1.28571429,  1.40816327,  1.53061224,  1.65306122,  1.7755102 ,\n",
    "        1.89795918,  2.02040816,  2.14285714,  2.26530612,  2.3877551 ,\n",
    "        2.51020408,  2.63265306,  2.75510204,  2.87755102,  3.        ])\n",
    "y = np.array([31.66815357, 31.26229494, 30.3467807 , 28.2057809 , 25.47674964,\n",
    "       22.81398414, 19.93953021, 19.38250362, 20.02551935, 17.44468883,\n",
    "       17.80733403, 16.29808282, 14.85006259, 12.69760597, 13.04075803,\n",
    "       10.42420089,  7.91118094,  9.72737214,  9.05962483,  6.89984054,\n",
    "        8.15068899,  5.15772899,  7.65448235,  4.95987628,  4.4284636 ,\n",
    "        3.22183541,  3.05456124,  3.49253584,  2.23478284,  4.15163314,\n",
    "        3.68063488,  5.22556445,  2.47139029,  2.66785497,  3.72557952,\n",
    "        2.56255802,  4.61385762,  4.28234911,  4.91138639,  5.31724926,\n",
    "        6.52053679,  5.94175001,  7.5368359 ,  9.78905172,  9.5795072 ,\n",
    "       10.95610291, 11.73051576, 12.85008617, 12.2184079 , 16.52977769])\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A polynomial estimator of degree 2 seems more appropriate in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function f of degree two with parameters (a,b,c)\n",
    "def f(x,a,b,c):\n",
    "    # INSERT YOUR CODE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to find the best params (a,b,c). We could again reuse `optimize.minimize` method to minimize the mean square error between our estimator $f$ and our scatter plot...\n",
    "\n",
    "Fortunately, the handy method [`scipy.optimize.curve_fit`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html) does just that in one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.17083046, -3.0087075 ,  4.31968534]),\n",
       " array([[ 2.83060958e-03,  5.70112271e-12, -8.83843408e-03],\n",
       "        [ 5.70112271e-12,  7.06225905e-03, -7.15333106e-11],\n",
       "        [-8.83843408e-03, -7.15333106e-11,  4.96491035e-02]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize.curve_fit(f, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first array contains coefs that have been computed to minimize square errors between $f$ and the dataset  .\n",
    "The second array contains the matrix of covariance.\n",
    "\n",
    "‚ùìPlot your quadratic estimator on top of the scatter plot to check that it fits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with any spreadsheet softwares, we often want to quickly fill the blanks in a series of datapoint. We'll use [`scipy.interpolate`](https://docs.scipy.org/doc/scipy/reference/interpolate.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's consider the following scatterplot\n",
    "x = np.linspace(0, 10, 10)\n",
    "y = np.array([ 0.        ,  0.8961922 ,  0.79522006, -0.19056796, -0.96431712,\n",
    "       -0.66510151,  0.37415123,  0.99709789,  0.51060568, -0.54402111])\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `interpolate.interp1d()` method to create a continuous function for any value $x$ in this range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_interpolated = interpolate.interp1d(x,y, kind='linear')\n",
    "f_interpolated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now call your interpolated function with any continuous values for $x$ in the initial range. Vizualize it with a new plot and a denser `linspace`for x. Feel free to try other `kind` of interpolations such as `quadratic` or `cubic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR PLOT HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "246px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
