{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Building Blocks of Gradient Descent\n",
    "\n",
    "Gradient descent is a fundamental part of machine learning and deep learning. This is the core of the mechanism used by the machine to \"learn\". In this exercise, we will approach the elements that you need to understand gradient descent.\n",
    "\n",
    "To learn a new motor skill, for instance, we produce gestures, get feedbacks and iterate to optimize the action. Algorithms are learning in a similar way.\n",
    "\n",
    "The workflow is the following:\n",
    "\n",
    "- 1. Start with some random parameter values: we call this random initialization. Zero initialization is also possible.\n",
    "- 2. Calculate the output of the algorithm with these parameters: this is call **forward propagation**.\n",
    "- 3. Calculate the error with these parameters: we compare the output of the algorithm with the ground truth (for this reason, we need the ground truth: this is a supervised algorithm).\n",
    "- 4. Evaluate how to change each parameter to reduce the error (let's consider this as a black box for now - we'll open the box in latter exercises) and update the parameters: this is called **backward propagation**.\n",
    "\n",
    "## 1. Data Exploration\n",
    "\n",
    "For this exercise, we'll use the [Ciqual dataset](https://ciqual.anses.fr/#) showing the composition of food.ðŸŒ½\n",
    "\n",
    "Let's start importing the libraries and loading a simplified version of the ciqual dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/ciqual_small.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this dataset to predict the amount of phosporus in food according to the amount of zinc.\n",
    "\n",
    "As usual, your first task is familiarize yourself with the data. You can:\n",
    "\n",
    "- 1. Display the first rows of the table with Pandas\n",
    "- 2. Get some description of the features (columns)\n",
    "- 3. Check that there is no missing values\n",
    "- 4. Visualize the relation between the variables `Phosphorus (mg/100g)` and `Zinc (mg/100g)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Forward Propagation\n",
    "\n",
    "In linear regression, the goal is to find the parameters of a line (a hyperplane of any number of dimensions) that fits well a set of data points. In this first part, you will code forward propagation using only one dimension. This means that we have only one feature and two parameters (the slope and the intercept of the line).\n",
    "\n",
    "This is a function taking parameter values as input and returning the prediction (we call prediction the value 'found' by the algorithm).\n",
    "\n",
    "In linear regression, we want to get the line parameters:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\theta_0 + \\theta_1x\n",
    "$$\n",
    "\n",
    "with $\\hat{y}$ the predicted value, $\\theta_0$ and $\\theta_1$ the model parameters (since this is the equation of a line, $\\theta_0$ corresponds to the intercept and $\\theta_1$ to the slope), and $x$ it the value of the input feature. For instance, if we use linear regression to predict the price of an apartment from the area in square meters, the input feature $x$ is the amount of square meter and $\\hat{y}$ is the predicted price.\n",
    "\n",
    "In this exercise, $\\hat{y}$ is the amount of phosphorus (what we try to predict) from our model and $x$ is the amount of zinc.\n",
    "\n",
    "Your task is first to create a function *hypothesis* `h()` (because it outputs a hypothetical result: the prediction) that takes $x$, $\\theta_0$ and $\\theta_1$ as inputs and return $\\hat{y}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def h(x, theta0, theta1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your function, here are few tests that you can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.564"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h(x=0.48, theta0=0.7, theta1=1.8)\n",
    "# should return 1.564"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.48"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h(x=0.48, theta0=2, theta1=1)\n",
    "# should return 2.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.19"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h(x=0.19, theta0=2, theta1=1)\n",
    "# should return 2.19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you managed to pass the tests, your forward propagation function is working!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loss Function - One Sample\n",
    "\n",
    "If you recall the workflow above, the first step is the parameter initialization. Easy: we'll start with random values for $\\theta_0$ and $\\theta_1$. The step 2. was the forward propagation that we just coded. So, we can now start the step 3: calculate the error of our model using the MSE.\n",
    "\n",
    "An loss function is a function that we use to compare a prediction ($\\hat{y}$) with the ground truth ($y$). The MSE loss function $L$ is defined with:\n",
    "\n",
    "$$\n",
    "L_{\\theta_0, \\theta_1} = \\sum_{i=0}^n (\\hat{y} - y)^2\n",
    "$$\n",
    "\n",
    "with $n$ the number of samples. For this first part, you will calculate the error for only one sample, so the equation simplifies to:\n",
    "\n",
    "$$\n",
    "L_{\\theta_0, \\theta_1} = (\\hat{y} - y)^2\n",
    "$$\n",
    "\n",
    "Let's initialize our parameters randomly and use seed to be sure that our results are reproducible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6964691855978616 0.28613933495037946\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "theta0 = np.random.rand()\n",
    "theta1 = np.random.rand()\n",
    "print(theta0, theta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your exercise is to implement the MSE function and calculate the error for the first 3 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alim_ssgrp_nom_eng</th>\n",
       "      <th>alim_nom_eng</th>\n",
       "      <th>Phosphorus (mg/100g)</th>\n",
       "      <th>Protein (g/100g)</th>\n",
       "      <th>Zinc (mg/100g)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pasta. rice and grains</td>\n",
       "      <td>Durum wheat pre-cooked. whole grain. cooked. u...</td>\n",
       "      <td>116.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pasta. rice and grains</td>\n",
       "      <td>Asian noodles. plain. cooked. unsalted</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pasta. rice and grains</td>\n",
       "      <td>Rice. brown. cooked. unsalted</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alim_ssgrp_nom_eng                                       alim_nom_eng  \\\n",
       "0  pasta. rice and grains  Durum wheat pre-cooked. whole grain. cooked. u...   \n",
       "1  pasta. rice and grains             Asian noodles. plain. cooked. unsalted   \n",
       "2  pasta. rice and grains                      Rice. brown. cooked. unsalted   \n",
       "\n",
       "   Phosphorus (mg/100g)  Protein (g/100g)  Zinc (mg/100g)  \n",
       "0                 116.0              5.25            0.48  \n",
       "1                  43.0              3.50            0.19  \n",
       "2                 120.0              3.21            0.62  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remind that we want to predict the amount of phosphorus from the amount of zinc.\n",
    "\n",
    "<details>\n",
    "  <summary>hint</summary>\n",
    "  You need to use your hypothesis function $h$ from above to calculate $\\hat{y}$.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your function, here are few tests that you can run. They correspond to the first 3 samples of the Ciqual dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13263.249921833765"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(x=0.48, y=116, theta0=theta0, theta1=theta1)\n",
    "# should return 13263.249921833765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1784.9918874926789"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(x=0.19, y=43, theta0=theta0, theta1=theta1)\n",
    "# should return 1784.9918874926789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14191.03352093345"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(x=0.62, y=120, theta0=theta0, theta1=theta1)\n",
    "# should return 1784.9918874926789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values correspond to the error of our model for each sample. It seems that the model is not very good, and this is normal, since it is just random for now ðŸ˜€.\n",
    "\n",
    "Now, you can try to plot the random regression line along with the data to have an idea of the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cost Function - Multiple Samples\n",
    "\n",
    "When applied to multiple data samples, we usually call *cost function* the function calculating the error of prediction.\n",
    "\n",
    "You will adapt the loss function from 3. to create the MSE cost function. This function will calculate the total error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the whole dataset and the random initialized parameters you should get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789086.39259691"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(x=data['Zinc (mg/100g)'], y=data['Phosphorus (mg/100g)'], theta0=theta0, theta1=theta1)\n",
    "# Should return 2789086.39259691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Grid Search to Find Parameters\n",
    "\n",
    "The last part of the linear regression algorithm is the optimization of our parameters $\\theta_0$ and $\\theta_1$. But first, we will look at a range of parameter values to the see the impact on the cost. You will do a grid search of parameters $\\theta_0$ and $\\theta_1$.\n",
    "\n",
    "- 1. Use your function from 4. to calculate the cost on the whole dataset using different values of $\\theta_0$ and $\\theta_1$.\n",
    "\n",
    "Use the following grid of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0_grid = np.arange(-500, 500, 50)\n",
    "theta1_grid = np.arange(-500, 500, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your function must take your variables `x`, `y`, `theta0_grid`, and `theta1_grid` as input and return a two-dimensional Numpy array containing the cost values corresponding to each combination of parameter $\\theta_0$ and $\\theta_1$.\n",
    "\n",
    "- 2. Store these value in a 2D Numpy array\n",
    "\n",
    "<details>\n",
    "<summary>hint</summary>\n",
    "You can create an array filled with 0. For instance,\n",
    "\n",
    "```python\n",
    "np.zeros((2, 2))\n",
    "```\n",
    "\n",
    "creates an array of shape $2 \\times 2$. You can then fill it with the parameter values.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def grid_search(x, y, theta0_grid, theta1_grid):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check your `grid_search()` function with the following test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27525475.0"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_all = grid_search(x=data['Zinc (mg/100g)'], y=data['Phosphorus (mg/100g)'],\n",
    "                       theta0_grid=theta0_grid, theta1_grid=theta1_grid)\n",
    "cost_all[12, 4]\n",
    "# Should return 27525475.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10732372.0"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_all[7, 18]\n",
    "# Should return 10732372.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3. Plot this matrix using a heatmap\n",
    "\n",
    "<details>\n",
    "<summary>hint</summary>\n",
    "https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an issue: since the parameters don't have the same scale, the \"good\" parameter values (the values that are associated with a low cost) are more spread on one dimension in comparison to the other. It is hard to visualize and to find the good parameters. We will also see later that it is not good for gradient descent to have features scaled differently.\n",
    "\n",
    "In our case, there is only one feature, we want to normalize it. We also want to normalize the dependent variable in order to insure that the bset parameters will be in the same range which will facilitate the search.\n",
    "\n",
    "Thus, your next task is to normalize the feature (amount of `zinc`) and the dependent variable (amount of `phosphorus`). To do so, you will create a normalization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will copy our dataset to be sure to keep it untouched and normalize the variables on the copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that your function is correct, run the following test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1.033903\n",
       "1   -1.299774\n",
       "2   -0.905552\n",
       "3   -1.235598\n",
       "4   -1.382285\n",
       "Name: Zinc (mg/100g), dtype: float64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(data_norm['Zinc (mg/100g)']).head()\n",
    "# Should return the following values:\n",
    "# 0    -1.033903\n",
    "# 1    -1.299774\n",
    "# 2    -0.905552\n",
    "# 3    -1.235598\n",
    "# 4    -1.382285"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When your `normalize()` function is correct:\n",
    "\n",
    "- 1. Use it to normalize the variables `zinc` and `phosphorus`.\n",
    "- 2. Visualize the scatter plot of the normalized data.\n",
    "- 3. Calculate the cost for every combination of parameter with the function `grid_search()` that you coded above.\n",
    "- 4. Visualize the new heatmap from normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom in a bit. You can repeat the same steps using a new range for our grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0_grid = np.arange(-2, 2, 0.2)\n",
    "theta1_grid = np.arange(-2, 2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing to do it to extract the parameters associated with the lower cost from the array `cost_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call `a` the slope corresponding to the best $\\theta_0$ and `b` the intercept corresponding to the best $\\theta_1$. You should have found the following parameters.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.440892098500626e-16 0.7999999999999994\n"
     ]
    }
   ],
   "source": [
    "print(a, b)\n",
    "# Should return -4.440892098500626e-16 0.7999999999999994"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the intercept is almost 0 and the slope is 0.8.\n",
    "\n",
    "Finally, you can plot the line with these parameters to see if it fits our data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
