{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text preprocessing consists of transforming raw text into a form that suits your task. The most basic transformations include removing punctuation, lower casing the text, removing numbers. More advanced are lemmatizing, remove stop words, Part of speech tagging. There are many more..\n",
    "\n",
    "It is important to chose the preprocessing steps that are suited to your task rather than systematically applying them. For example, if you are trying to predict the date of certain texts, numbers may be important.\n",
    "\n",
    "In this exercice you will learn some basic text preprocessing and apply it to the following sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example = \"02/12/2018. The world loves Zlatan Ibrahimovic. He is such an amaZing Footballer!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the function to remove punctuation and apply it to the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    # Code Here\n",
    "    return no_punc\n",
    "\n",
    "stepbystep = remove_punctuation(example) \n",
    "\n",
    "stepbystep #You will apply the following functions to stepbystep to visualize changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the function and apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase (text): \n",
    "    # Code Here\n",
    "    return lowercased\n",
    "\n",
    "stepbystep = lowercase(stepbystep) #Remember, apply function to stepbystep\n",
    "\n",
    "stepbystep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing splits up a text into a list of individual words, also called tokens. Complete the function to do so. Apply to stepbystep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize (text):\n",
    "    # Code Here\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that removes numbers and apply to stepbystep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove StopWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Stopwords\" are words are so frequently used that for many tasks (but not all), they don't carry much information. Examples are \"any\", \"all\", \"what\"... NLTK has an inbuilt corpus of english stopwords that can be loaded and used. \n",
    "\n",
    "Using that corpus, create a function to remove StopWords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizing consists of reducing word derivatives down to their ethymological roots. For example: studies & studying --> study.\n",
    "\n",
    "First, initiate a WordNetLemmatizer using the NLTK package. Then use it to lemmatize text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all of the above steps into one single function, then apply it to the original sentence \"example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code Here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
