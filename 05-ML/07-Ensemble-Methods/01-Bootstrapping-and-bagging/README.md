## Bootstrapping and Bagging

In this challenge, you will implement bootstrapping (aka resampling) and bagging (aka bootstrap aggregating). These are key concepts to understand the Random Forest. We will discover this method in the next exercise.

Random forests are **an ensemble learning method** for classification, regression and other tasks. It operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (for classification) or mean prediction (for regression) of the individual trees. Random forests correct for decision trees habit of overfitting to their training set.

Open jupyter notebook, and follow the instructions ðŸ¤“.

![Random Forest Classifier](https://miro.medium.com/max/592/1*i0o8mjFfCn-uD79-F1Cqkw.png)
