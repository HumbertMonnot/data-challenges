{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...\n",
       "1  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "2  From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...\n",
       "3  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "4  From: vzhivov@superior.carleton.ca (Vladimir Z..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data', sep=\",\", header=None)\n",
    "\n",
    "data.columns = ['text']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a collection of emails that are not labelled. Let's try extract topics from them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ You're used to it by now... Clean up! Store the cleaned text in a new dataframe column \"clean_text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>from  gld cunixb cc columbia edu  gary l dare ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>from  atterlep vela acs oakland edu  cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>from  miner kuhub cc ukans edu\\nsubject  re  a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>from  atterlep vela acs oakland edu  cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>from  vzhivov superior carleton ca  vladimir z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>from  jerryb eskimo com  jerry kaufman \\nsubje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>from  golchowy alchemy chem utoronto ca  geral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>from  jayne mmalt guild org  jayne kulikauskas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>from  sclark epas utoronto ca  susan clark \\ns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>from  lmvec westminster ac uk  william hargrea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     from  gld cunixb cc columbia edu  gary l dare ...\n",
       "1     from  atterlep vela acs oakland edu  cardinal ...\n",
       "2     from  miner kuhub cc ukans edu\\nsubject  re  a...\n",
       "3     from  atterlep vela acs oakland edu  cardinal ...\n",
       "4     from  vzhivov superior carleton ca  vladimir z...\n",
       "...                                                 ...\n",
       "1194  from  jerryb eskimo com  jerry kaufman \\nsubje...\n",
       "1195  from  golchowy alchemy chem utoronto ca  geral...\n",
       "1196  from  jayne mmalt guild org  jayne kulikauskas...\n",
       "1197  from  sclark epas utoronto ca  susan clark \\ns...\n",
       "1198  from  lmvec westminster ac uk  william hargrea...\n",
       "\n",
       "[1199 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "\n",
    "def remove_punct(df_to_treat):\n",
    "    dataf = df_to_treat.copy()\n",
    "    for col in dataf:\n",
    "        if dataf[col].dtype == 'O':\n",
    "            for punct in string.punctuation:\n",
    "                dataf[col] = [text.replace(punct, ' ') for text in dataf[col]]\n",
    "    return dataf\n",
    "\n",
    "def lower_func(df_to_treat):\n",
    "    dataf = df_to_treat.copy()\n",
    "    for col in dataf:\n",
    "        if dataf[col].dtype == 'O':\n",
    "            for punct in string.punctuation:\n",
    "                dataf[col] = [text.lower() for text in dataf[col]]\n",
    "    return dataf\n",
    "\n",
    "clean_data = lower_func(remove_punct(data))\n",
    "clean_data\n",
    "\n",
    "def remove_nb(df_to_treat):\n",
    "    dataf = df_to_treat.copy()\n",
    "    for col in dataf:\n",
    "        if dataf[col].dtype == 'O':\n",
    "            dataf[col] = [''.join(word for word in text if not word.isdigit()) for text in dataf[col]]\n",
    "    return dataf\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def remove_sw(df_to_treat):\n",
    "    dataf = df_to_treat.copy()\n",
    "    for col in dataf:\n",
    "        if dataf[col].dtype == 'O':\n",
    "            dataf[col] = [[w for w in word_tokenize(text) if not w in stop_words] for text in dataf[col]]\n",
    "    return dataf\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemm_func(df_to_treat):\n",
    "    dataf = df_to_treat.copy()\n",
    "    for col in dataf:\n",
    "        if dataf[col].dtype == 'O':\n",
    "            dataf[col] = [\" \".join([lemmatizer.lemmatize(word) for word in text]) for text in dataf[col]]\n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'married'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"married\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gld cunixb cc columbia edu gary l dare subject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atterlep vela ac oakland edu cardinal ximenez ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>miner kuhub cc ukans edu subject ancient book ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atterlep vela ac oakland edu cardinal ximenez ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vzhivov superior carleton ca vladimir zhivov s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>jerryb eskimo com jerry kaufman subject prayer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>golchowy alchemy chem utoronto ca gerald olcho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>jayne mmalt guild org jayne kulikauskas subjec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>sclark epa utoronto ca susan clark subject pic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>lmvec westminster ac uk william hargreaves sub...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     gld cunixb cc columbia edu gary l dare subject...\n",
       "1     atterlep vela ac oakland edu cardinal ximenez ...\n",
       "2     miner kuhub cc ukans edu subject ancient book ...\n",
       "3     atterlep vela ac oakland edu cardinal ximenez ...\n",
       "4     vzhivov superior carleton ca vladimir zhivov s...\n",
       "...                                                 ...\n",
       "1194  jerryb eskimo com jerry kaufman subject prayer...\n",
       "1195  golchowy alchemy chem utoronto ca gerald olcho...\n",
       "1196  jayne mmalt guild org jayne kulikauskas subjec...\n",
       "1197  sclark epa utoronto ca susan clark subject pic...\n",
       "1198  lmvec westminster ac uk william hargreaves sub...\n",
       "\n",
       "[1199 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = lemm_func(remove_sw(remove_nb(clean_data)))\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ Train an LDA model to extract potential topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer().fit(clean_data['text'])\n",
    "\n",
    "data_vectorized = vectorizer.transform(clean_data['text'])\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=10).fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize potential topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ The function to print the words associated with the potential topics is already made for you. You just have to pass the correct arguments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('married', 4.705499797201052), ('marriage', 4.541112570250016), ('pope', 3.442161479890475), ('ceremony', 2.3560648896926004), ('jcj', 2.2024051265073648), ('eye', 2.1674535586790267), ('temple', 2.037488587276869), ('priest', 1.860301499941912), ('bishop', 1.6884242457801861), ('marry', 1.5888398966340005)]\n",
      "Topic 1:\n",
      "[('georgia', 4.4822418298030815), ('ai', 4.39433095328003), ('fisher', 3.8751187881926175), ('indiana', 3.835869373061983), ('uga', 3.756890955379642), ('athens', 3.263873046972323), ('covington', 3.100494101159468), ('sabbath', 2.9996534586707604), ('mcovingt', 2.9841736843499693), ('darius', 2.6344921162094126)]\n",
      "Topic 2:\n",
      "[('babylon', 1.2418487727994154), ('darren', 1.2201192331401791), ('infallible', 1.0414174197526616), ('rowan', 1.0305854419813678), ('pregnancy', 0.9154583796427921), ('tom', 0.8744659234469662), ('kilroy', 0.8564873700940343), ('gboro', 0.856487370093691), ('dlmqc', 0.7703898307329172), ('albrecht', 0.7262032430603643)]\n",
      "Topic 3:\n",
      "[('god', 34.12089210569954), ('christian', 22.21700256202835), ('jesus', 17.98467738920302), ('edu', 16.826633822374646), ('one', 15.733816859229368), ('people', 15.525114285012053), ('would', 15.113725180792802), ('church', 15.002109109599981), ('bible', 12.706419447614717), ('believe', 12.461277273733225)]\n",
      "Topic 4:\n",
      "[('resurrection', 3.5726131300033734), ('hammerl', 2.881299159111361), ('mussack', 2.863184247319386), ('wustl', 2.4967984188910752), ('cec', 2.1791645147888925), ('acsu', 2.1004066093240015), ('plymouth', 1.733892771169768), ('ibm', 1.7173706261209247), ('easter', 1.6801952121895067), ('ncsu', 1.657250766140568)]\n",
      "Topic 5:\n",
      "[('edu', 25.924332527687465), ('game', 24.624166242455434), ('team', 23.44993098271481), ('ca', 21.26898317755427), ('hockey', 17.478226668100724), ('player', 16.54733890830066), ('go', 14.645948878080057), ('play', 13.702554340565525), ('year', 13.53272828283389), ('university', 12.529230381055413)]\n",
      "Topic 6:\n",
      "[('celebration', 1.1897589630460972), ('milwaukee', 0.8034730660665589), ('halat', 0.7771710315617315), ('godhead', 0.7422683029185149), ('jung', 0.695297792104749), ('albany', 0.6779146777294924), ('huot', 0.6676200750085313), ('cf', 0.6412163528148253), ('nyx', 0.6323601192626329), ('cray', 0.6310348347652153)]\n",
      "Topic 7:\n",
      "[('pp', 2.9523467826650722), ('darling', 1.5558530716767303), ('andersson', 1.3355577083627412), ('cellar', 1.3042080748151048), ('holger', 1.1727536432654055), ('zubov', 1.0228615144047188), ('ohlwein', 1.019500686545144), ('cassels', 0.8927572232646139), ('nylander', 0.8904223551598046), ('cadkey', 0.855305671309678)]\n",
      "Topic 8:\n",
      "[('liturgy', 2.1724095888912345), ('ayari', 1.754415828504298), ('min', 1.511870436789887), ('passion', 1.4638008676359595), ('mtl', 1.246125339047255), ('loria', 1.2460598481612566), ('fr', 1.1923889728800892), ('sabbath', 1.1503012687696126), ('chant', 1.0944360422965709), ('iskander', 1.0229241725662517)]\n",
      "Topic 9:\n",
      "[('heath', 1.5484646419195474), ('dreier', 1.1992946922618728), ('watt', 1.1883739326972156), ('model', 1.1338981197634552), ('testing', 1.0997763502363307), ('bassili', 0.9859544047337125), ('interior', 0.9583535871920539), ('utk', 0.947198140002606), ('delab', 0.9358736253207689), ('secretary', 0.887818999081113)]\n"
     ]
    }
   ],
   "source": [
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])\n",
    "        \n",
    "\n",
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict topic of new text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ You can now use your LDA model to predict the topic of a new text. First, use your vectorizer to vectorize the example. Then, use your LDA model to predict the topic of the vectorized example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le probabilitÃ© d'Ãªtre dans le Topic 0 est de : 0.024695404827896117\n",
      "Le probabilitÃ© d'Ãªtre dans le Topic 1 est de : 0.02469540400409921\n",
      "Le probabilitÃ© d'Ãªtre dans le Topic 2 est de : 0.024695405683845508\n",
      "Le probabilitÃ© d'Ãªtre dans le Topic 3 est de : 0.14523043891838258\n",
      "Le probabilitÃ© d'Ãªtre dans le Topic 4 est de : 0.024695403882919766\n",
      "Le probabilitÃ© d'Ãªtre dans le Topic 5 est de : 0.6572063184336685\n",
      "Le probabilitÃ© d'Ãªtre dans le Topic 6 est de : 0.024695406257364605\n",
      "Le probabilitÃ© d'Ãªtre dans le Topic 7 est de : 0.024695406027295586\n",
      "Le probabilitÃ© d'Ãªtre dans le Topic 8 est de : 0.024695406091351374\n",
      "Le probabilitÃ© d'Ãªtre dans le Topic 9 est de : 0.02469540587317669\n"
     ]
    }
   ],
   "source": [
    "example = [\"My team performed poorly last season. Their best player was out injured and only played one game\"]\n",
    "\n",
    "to_test = lemm_func(remove_sw(remove_nb(lower_func(remove_punct(pd.DataFrame(example))))))\n",
    "to_test[0]\n",
    "example_vectorized = vectorizer.transform(to_test[0])\n",
    "\n",
    "res = lda_model.transform(example_vectorized)\n",
    "\n",
    "for top in range(len(res[0])):\n",
    "    print(f\"Le probabilitÃ© d'Ãªtre dans le Topic {top} est de : {res[0][top]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
