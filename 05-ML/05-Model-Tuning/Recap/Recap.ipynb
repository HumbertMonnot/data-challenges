{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (1000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    599\n",
       "1    299\n",
       "2    102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a dummy \"wine\" dataset of 1000 wines, 10 features, and 3 classes (0=bad, 1=medium, 2=good wine)\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=10, n_classes=3, n_clusters_per_class=1, weights=[0.6, 0.3, 0.1], random_state=0\n",
    ")\n",
    "print(\"X.shape = \", X.shape)\n",
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "❓ Our objective is to train a model which **maximizes prediction precision for the good wines (y=2) only**.  \n",
    "\n",
    "We don't want any customers to be dissatisfied!\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to gridsearch SVC classifiers (for instance)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, gamma=0.005)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's CV the \"best\" SVC for \"accurary\" first (default perf metrics for SVC)\n",
    "param_grid = {\n",
    "    \"kernel\": ['rbf', 'linear'],\n",
    "    \"C\": [0.1, 0.05, 1, 5, 10, 50, 100],\n",
    "    \"gamma\": [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       176\n",
      "           1       0.88      0.92      0.90        93\n",
      "           2       0.80      0.65      0.71        31\n",
      "\n",
      "    accuracy                           0.91       300\n",
      "   macro avg       0.87      0.84      0.85       300\n",
      "weighted avg       0.91      0.91      0.91       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, clf.best_estimator_.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we want to optimize for precision of feature 2 only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.611111111111111"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need a metric for our multi-class problem. Let's try sklearn \"precision_score\"\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "_true = [0,0,1,2,2,1]\n",
    "_pred = [0,1,1,2,1,0]\n",
    "\n",
    "precision_score(_true,_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☝️ Not good enough, we want to focus **only** on class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's make our own custom metrics which gives only the precision of class \"2\"\n",
    "# TP2/(TP2+FN2.1+FN2.0)\n",
    "def my_custom_metric(y_true, y_pred):\n",
    "    acc_tot = 0\n",
    "    acc_tp = 0\n",
    "    \n",
    "    for (idx, y_p) in enumerate(y_pred):\n",
    "        if y_p ==2:\n",
    "            acc_tot +=1\n",
    "            if y_true[idx] == 2:\n",
    "                acc_tp +=1\n",
    "    \n",
    "    if acc_tot == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return acc_tp/acc_tot\n",
    "\n",
    "\n",
    "_true = [0,0,1,2,2,1]\n",
    "_pred = [0,1,1,2,1,0]\n",
    "\n",
    "my_custom_metric(_true, _pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's try to plug that into sklearn (will crash)\n",
    "GridSearchCV(SVC(), param_grid, cv=5, scoring=my_custom_metric).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to transform our \"metric\" into a \"sklearn scorer method\"\n",
    "from sklearn.metrics import make_scorer\n",
    "my_custom_scorer = make_scorer(my_custom_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, gamma=0.0005)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then we do another GridSearch with this custom scorer\n",
    "\n",
    "clf = GridSearchCV(SVC(), param_grid, cv=5, scoring=my_custom_scorer)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       176\n",
      "           1       0.79      0.87      0.83        93\n",
      "           2       1.00      0.26      0.41        31\n",
      "\n",
      "    accuracy                           0.86       300\n",
      "   macro avg       0.90      0.70      0.72       300\n",
      "weighted avg       0.87      0.86      0.84       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, clf.best_estimator_.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ We improved our precision for class 2 from 0.8 up to 1, but at the detriment of overall accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
