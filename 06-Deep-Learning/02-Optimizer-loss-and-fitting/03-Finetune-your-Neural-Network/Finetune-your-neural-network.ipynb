{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune your Neural Network\n",
    "\n",
    "### Exercise objectives:\n",
    "- Finetune the model optimizer\n",
    "- Save and load a neural network\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "Now that you have mastered almost every part of Neural Networks, let's take a closer look at the `compile` part.\n",
    "\n",
    "# Data\n",
    "\n",
    "We will here use the data from the Boston Housing dataset\n",
    "\n",
    "❓ **Question** ❓ First, load the data with the appropriate function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ To get a sense of a benchmark score you have to beat, what is the mean absolute error on the test set if your prediction corresponds to the mean value of $y$ computed on the train set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The model\n",
    "\n",
    "❓ **Question** ❓ Now, write in a function `initialize_model` a neural network that has 3 layers: \n",
    "- a layer with 10 neurons and the `relu` activation function (appropriate input dimension)\n",
    "- a layer with 7 neurons and the `relu` activation function\n",
    "- an appropriate layer corresponding to the problem at hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The optimizer\n",
    "\n",
    "❓ **Question** ❓ Write a function that takes as argument a model and a name of optimizer, that compiles the model and returns it - select the loss and metrics wisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, optimizer_name):\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Initialize the model, compile it with the `adam` optimizer and fit it on the data. Evaluate your model on the test data.\n",
    "\n",
    "Do not forget to use an early stopping criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Rerun the same model on the same data but with different optimizer (in a `for` loop). For each, plot the history and report the corresponding Mean Absolute Error. (see [here](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)), as well as the time it took to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_mae(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(13,4))\n",
    "    ax1.plot(history.history['loss'])\n",
    "    ax1.plot(history.history['val_loss'])\n",
    "    ax1.set_title('Model loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylim(ymin=0, ymax=200)\n",
    "    ax1.legend(['Train', 'Validation'], loc='best')\n",
    "    \n",
    "    ax2.plot(history.history['mae'])\n",
    "    ax2.plot(history.history['val_mae'])\n",
    "    ax2.set_title('MAE')\n",
    "    ax2.set_ylabel('MAE')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylim(ymin=0, ymax=20)\n",
    "    ax2.legend(['Train', 'Validation'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Are your predictions better than the benchmark prediction you evaluate at the beginning of the notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗ **Remark** ❗ \n",
    "- Here, the optimizer is may not be central as the data are in low dimension and not many samples. However, in practice, you are advised to start with the `adam` optimizer by default which often works best. \n",
    "\n",
    "- Internally, when you call any optimizer with a string, the neural network initializes the hyperparameters the optimizer rely on. Among this hyperparameters, there is quite an important one, the learning rate. This learning rate corresponds to the intensity of change of the weights at each optimization of the neural network. Different learning rates have different consequences, as shown here : \n",
    "\n",
    "<img src=\"learning_rate.png\" alt=\"Learning rate\" style=\"height:350px;\"/>\n",
    "\n",
    "\n",
    "As the learning rate is initialized with default values when you compile the model optimizer with a string, let's see how to do it differently.\n",
    "\n",
    "\n",
    "❓ **Question** ❓ Instead of initializing the optimizer with a string, we will initialize a real optimizer directly. Look at the documentation of [adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and instanciate it with a learning rate of 0.1 - keep the other values to their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Use this optimizer in the `compile_model` function, fit the data and plot the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Now, reproduce the same plots and results but for different learning rates.\n",
    "\n",
    "Remark: There is a chance that the y-axis is too large for you to visualize the results. In that case, rewrite the plot function to plot only the epochs > 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.0001, 0.001, 0.01, 0.1, 1, 5]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Advanced (exponential decay)\n",
    "\n",
    "The next question is optional and intended for advanced users that are willing to go a step further in their Deep Learning skills. However, it is not essential and can be skiped as many algorithms can be run without such optimization. \n",
    "\n",
    "Instead of keeping a fixed learning rate, you can change it from one iteration to the other, with the intuition that you first need large learning rates, and as the neural network converges and get closer to the minimum, you decrease the value of the learning rate. This is called a scheduler. \n",
    "\n",
    "❓ **Question** ❓ Use the [exponential decay scheduler](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay) in the adam optimizer and run it on the previous data. Start with the following\n",
    "\n",
    "```python\n",
    "initial_learning_rate = 0.001 # start with default ADAM value\n",
    "\n",
    "lr_schedule = ExponentialDecay(\n",
    "    # Every 5000 iterations, multiply the learning rate by 0.7\n",
    "    initial_learning_rate, decay_steps=5000, decay_rate=0.7,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. The loss\n",
    "\n",
    "It is important to clearly understand the different between metrics and loss. The loss are part of the metrics, therefore some metrics can be used as loss.\n",
    "\n",
    "❓ **Question** ❓ Run the same neural network, once with the `mae` as the loss, and once with the `mse`.  \n",
    "\n",
    "In both case, compare `mae_train`, `mae_test`, `mse_train`, `mse_test` and conclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗️ Countrary to first intuition, it can be better to use the MSE as the loss so as to get the best MAE possible in the end!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Why?</summary>\n",
    "\n",
    "Well, even the Deep Learning research community is still trying to answer these types of questions rigorously.\n",
    "    \n",
    "One thing for sure: In deep learning, you never really reach the \"global minimum\" of the true loss function (the one computed using your entire training set as one single \"batch\"). So, in your first model (minimizing the MAE loss), your global MAE minimum has clearly **not** been reached (otherwise you could never beat it). \n",
    "\n",
    "Why? It may well be that the minimization process of the second model has better performed. Maybe because the loss function \"energy map\" is \"smoother\" or more \"convex\" in the case of MSE loss? Or maybe your hyper-parameter are best suited to the MSE than to the MAE loss?\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 : Save and load a model\n",
    "\n",
    "Here, we will see how to save a model, and load it afterwards.\n",
    "\n",
    "❓ **Question** ❓ Rerun any model you want and evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Now, save the model thanks to the `save_model` method that you can find [here](https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Now, in a variable `loaded_model`, load the model you just saved thanks to the `load_model` [(documentation here)](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model), and evaluate it on the test data to see that it gives the same result as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pm455OX6ksyl"
   },
   "source": [
    "# 5: Regularization\n",
    "\n",
    "In this part of the notebook, we will see how to use regularizers in a neural network. Regularizers are used to prevent overfitting that can happends because very complex networks have many many parameters which tends to overfit the training data.\n",
    "\n",
    "❓ **Question** ❓ First, initialize a model that has a lot of parameters (many layers and/or many neurons) such that it overfits the training data (to better see the effect, do not use any early stopping criterion). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGkb0K3Nksym"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 81596,
     "status": "ok",
     "timestamp": 1612905145614,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -60
    },
    "id": "XaOTe0-Yksyn"
   },
   "outputs": [],
   "source": [
    "def initialize_model_2():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(1000, activation='relu', input_dim=13))\n",
    "    model.add(layers.Dense(750, activation='relu'))\n",
    "    model.add(layers.Dense(500, activation='relu'))\n",
    "    model.add(layers.Dense(500, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = initialize_model_2()\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data = (X_test, y_test),\n",
    "                  batch_size=16, \n",
    "                  epochs=1000, \n",
    "                  verbose=0)\n",
    "\n",
    "res = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03ZOjwm2ksyo"
   },
   "source": [
    "In your overparametrized network, some neurons got too specific to given training data, preventing the network from generalizing to new data. This lead to some overfitting. \n",
    "\n",
    "For that reason, we will use \n",
    "\n",
    "- dropout layers, whose role is to _cancel_ the output of some neurons  during the training part. By doing this at random, it prevents the network from getting too specific to the input data : no any neuron can be too specific to a given input as its output is sometimes cancelled by the dropout layer. Overall, it forces the information that is contain in one input sample to go through multiple neurons instead of only one specific.\n",
    "\n",
    "- Regularization of the outputs of a layer, as in linear regression regularization where the weights of the linear regression are constrained by L1, L2 or L1 and L2 norms. Such regularization can be done at each layer for:\n",
    "  - all the biases of the layer, with `bias_regularizer` argument\n",
    "  - all the weights of the layer, with the `kernel_regularizer` argument\n",
    "  - the outputs of the layer (after the activity function) with the `activity_regularizer` argument\n",
    "\n",
    "\n",
    "❓ **Question** ❓ Try adding dropout layers and regularization to all your layers of the above neural network and look at the effect on the loss on the test set.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xBUGKa4ksys"
   },
   "source": [
    "There are other ways to prevent overfitting in a neural network. The standard one (apart Dropout) is to \n",
    "\n",
    "❓ **Question** ❓ Add some of the previous regularizers to the Dense layers of your previous neural networks - and without dropout layers, as it can interact in a way that you are not sure of. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRMeffBOksys"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkKk_3Keksyw"
   },
   "source": [
    "Remark: You probably have seen very little difference in the previous examples. This is due to the simplicity of the data. However, in other cases, especially in the last exercice (open challenge), the data are more complex, and for some architectures, you might encounter overfitting that you can prevent thanks to regularization techniques as overfitting or L1/L2 regularizations.\n",
    "\n",
    "# Part VI : Get the best Mean Absolute Error\n",
    "\n",
    "From here, you are free to:\n",
    "- design your own architecture: number of layers, number of neurons, activation function\n",
    "- choose the loss and metric\n",
    "- choose the optimizer and tune its hyperparameters\n",
    "- select the best options for the early stopping criterion\n",
    "\n",
    "to get the best mean absolute error.\n",
    "\n",
    "Once you have your best score on the test set, include the whole pipeline into a proper cross validation to report your score (mean ± std).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
