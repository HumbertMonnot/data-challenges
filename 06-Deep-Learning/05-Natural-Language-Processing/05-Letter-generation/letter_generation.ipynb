{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter generation\n",
    "\n",
    "### Exercise objective\n",
    "- Get autonomous with Natural Language Processing\n",
    "- Generate Letter\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "In this exercise, we will try to generate some text. The underlying idea is to give a input sequence and to predict what the next letter is going to be. To do that, we will first create a dataset for this task, and then run a RNN to do the prediction.\n",
    "\n",
    "# The data\n",
    "\n",
    "❓ Question ❓ First, let's load the data. Here, it is the IMDB reviews again, but we are only interested in the sentences, not the positiveness or negativeness of the review. \n",
    "\n",
    "⚠️ **Warning** ⚠️ The `load_data` function has a `percentage_of_sentences` argument. Depending on your computer, there are chances that a too large number of sentences will make your compute slow down, or even freeze - your RAM can even overflow. For that reason, you can start with 20% of the sentences and see if your computer handles it. Otherwise, rerun with a lower number. On the other hand, you can increase the number if you feel like it. \n",
    "\n",
    "**At the end of the notebook, to improve the model, you would maybe need to increase the number of loaded sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/humbert/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/Users/humbert/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "def load_data(percentage_of_sentences=None):\n",
    "    # Load the data\n",
    "    (sentences_train, y_train), (sentences_test, y_test) = imdb.load_data()\n",
    "    \n",
    "    # Take only a given percentage of the entire data\n",
    "    if percentage_of_sentences is not None:\n",
    "        assert(percentage_of_sentences> 0 and percentage_of_sentences<=100)\n",
    "        \n",
    "        len_train = int(percentage_of_sentences/100*len(sentences_train))\n",
    "        sentences_train = sentences_train[:len_train]\n",
    "        y_train = y_train[:len_train]\n",
    "        \n",
    "        len_test = int(percentage_of_sentences/100*len(sentences_test))\n",
    "        sentences_test = sentences_test[:len_test]\n",
    "        y_test = y_test[:len_test]\n",
    "            \n",
    "    # Load the {interger: word} representation\n",
    "    word_to_id = imdb.get_word_index()\n",
    "    word_to_id = {k:(v+3) for k,v in word_to_id.items()}\n",
    "    for i, w in enumerate(['<PAD>', '<START>', '<UNK>', '<UNUSED>']):\n",
    "        word_to_id[w] = i\n",
    "\n",
    "    id_to_word = {v:k for k, v in word_to_id.items()}\n",
    "\n",
    "    # Convert the list of integers to list of words (str)\n",
    "    X_train = [' '.join([id_to_word[_] for _ in sentence[1:]]) for sentence in sentences_train]\n",
    "    \n",
    "    return X_train\n",
    "\n",
    "\n",
    "### Just run this cell to load the data\n",
    "X = load_data(percentage_of_sentences=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Write a function that, given a string (list of letters), returns\n",
    "- a string (list of letters) that corresponds to part of the sentence  - this string should be of size 300\n",
    "- the letter that follow the previous string\n",
    "\n",
    "❗ **Remark** ❗ There is no reason your first strings to start by the beginning of the input string.\n",
    "\n",
    "Example:\n",
    "- Input : 'This is a good movie\"\n",
    "- Output: ('a good m', 'o') [Except the first part should be of size 300 instead of 8]\n",
    "\n",
    "❗ **Remark** ❗ If the input is shorter than 300 letters, return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "def part_sent(sentence):\n",
    "    if len(sentence)<302:\n",
    "        return None\n",
    "    i = len(sentence)-302\n",
    "    begin_index = np.random.randint(0,i)\n",
    "    return (sentence[begin_index:begin_index+300], sentence[begin_index+300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Check that the function is working on some strings from the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('re was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and yo',\n",
       " 'u')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_sent(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Write a function, that, based on the previous function and the loaded sentences, generate a dataset X and y:\n",
    "- each sample of X is a string\n",
    "- the corresponding y is the letter that comes just after in the input string\n",
    "\n",
    "❗ **Remark** ❗ This question is not much guided as it is similar to what you have done in the previous exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(nb):\n",
    "    dataX = []\n",
    "    datay = []\n",
    "    count = nb\n",
    "    while count != 0:\n",
    "        index = np.random.randint(0,len(X))\n",
    "        if part_sent(X[index])!=None :\n",
    "            xi, yi = part_sent(X[index])\n",
    "            dataX.append(xi)\n",
    "            datay.append(yi)\n",
    "            count = count - 1\n",
    "    return dataX, datay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"racker bag last night before a preview screening of disney's holes i don't know who decided to show it but i'm so very glad they did cracker bag is an absolute gem a snapshot of australia in the early 80s as seen through a child's eye the conversations between eddie and her brother were hilarious an\",\n",
       "  \"at much of the world we are seeing is about to be swept away in the cataclysm of world war 2 and the communist revolution br br which makes the central character's desire to adhere to old customs and traditions all the more poignant br br but the film also raises issues which are of vital importance\",\n",
       "  \"why damn fox canceled the season3 although season2 was not as good as season1 which is excellent indeed i like it so much that i even thinking about buying dvd on amazon failed i am a chinese student and it's inconvenient for me to get a international credit card and i just hope fox can bring back d\",\n",
       "  'y happened viewers will recognize his co workers the actors clarence kolb donald macbride don beddoe always played positions of authority senators bank presidents policemen this who dunnit has a flair of comedy to it the policemen are always throwing jabs at each other and even williams and his girl'],\n",
       " ['d', ' ', 'a', 'f'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Split X and y in train and test data. Store it in `string_train`, `string_test`, `y_train` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "string, letter = data_gen(7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_train, string_test, y_train, y_test = train_test_split(string, letter, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Create a dictionary which stores a unique token for each letter: the key is the letter while the value is the corresponding token. You have to build you dictionary based on the letters that are in `string_train` and `y_train` only, as you are not supposed to know the test set (and the new letters that might appear, which is unlikely, but still possible).\n",
    "\n",
    "❗ **Remark** ❗ To account for the fact that there might be letters in the test set that are not in the train set, add a particular token for that, whose corresponding key can be `UNKNOWN`.\n",
    "\n",
    "❗ **Remark** ❗ By letter, we actually mean any character. As there happen to be numbers (`1`, `2`, ...) or `?`, `!`, `@`, ... in texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5600"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "big_string = \"\".join(string_train) + \"\".join(y_train)\n",
    "\n",
    "tokenizer = Tokenizer(char_level=True, oov_token='UNKNOWN')\n",
    "tokenizer.fit_on_texts(\"\".join(string_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_size = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61,\n",
       " {'UNKNOWN': 1,\n",
       "  ' ': 2,\n",
       "  'e': 3,\n",
       "  't': 4,\n",
       "  'a': 5,\n",
       "  'i': 6,\n",
       "  'o': 7,\n",
       "  's': 8,\n",
       "  'n': 9,\n",
       "  'r': 10,\n",
       "  'h': 11,\n",
       "  'l': 12,\n",
       "  'd': 13,\n",
       "  'c': 14,\n",
       "  'm': 15,\n",
       "  'u': 16,\n",
       "  'f': 17,\n",
       "  'y': 18,\n",
       "  'g': 19,\n",
       "  'w': 20,\n",
       "  'b': 21,\n",
       "  'p': 22,\n",
       "  'v': 23,\n",
       "  'k': 24,\n",
       "  \"'\": 25,\n",
       "  'j': 26,\n",
       "  'x': 27,\n",
       "  'z': 28,\n",
       "  'q': 29,\n",
       "  '0': 30,\n",
       "  '1': 31,\n",
       "  '9': 32,\n",
       "  '2': 33,\n",
       "  '3': 34,\n",
       "  '5': 35,\n",
       "  '4': 36,\n",
       "  '7': 37,\n",
       "  '8': 38,\n",
       "  '6': 39,\n",
       "  'é': 40,\n",
       "  '\\x96': 41,\n",
       "  '\\x85': 42,\n",
       "  '´': 43,\n",
       "  'ä': 44,\n",
       "  '\\x97': 45,\n",
       "  'ç': 46,\n",
       "  'ï': 47,\n",
       "  'ã': 48,\n",
       "  'è': 49,\n",
       "  '“': 50,\n",
       "  '”': 51,\n",
       "  'å': 52,\n",
       "  'ö': 53,\n",
       "  'à': 54,\n",
       "  'ü': 55,\n",
       "  '–': 56,\n",
       "  '’': 57,\n",
       "  'ó': 58,\n",
       "  'ù': 59,\n",
       "  'í': 60,\n",
       "  '\\xa0': 61})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index), tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Based on the previous dictionary, tokenize the strings and stores them in `X_train` and `X_tests`.\n",
    "\n",
    "❗ **Remark** ❗ Convert your lists to NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UNKNOWN': 1,\n",
       " ' ': 2,\n",
       " 'e': 3,\n",
       " 't': 4,\n",
       " 'a': 5,\n",
       " 'i': 6,\n",
       " 'o': 7,\n",
       " 's': 8,\n",
       " 'n': 9,\n",
       " 'r': 10,\n",
       " 'h': 11,\n",
       " 'l': 12,\n",
       " 'd': 13,\n",
       " 'c': 14,\n",
       " 'm': 15,\n",
       " 'u': 16,\n",
       " 'f': 17,\n",
       " 'y': 18,\n",
       " 'g': 19,\n",
       " 'w': 20,\n",
       " 'b': 21,\n",
       " 'p': 22,\n",
       " 'v': 23,\n",
       " 'k': 24,\n",
       " \"'\": 25,\n",
       " 'j': 26,\n",
       " 'x': 27,\n",
       " 'z': 28,\n",
       " 'q': 29,\n",
       " '0': 30,\n",
       " '1': 31,\n",
       " '9': 32,\n",
       " '2': 33,\n",
       " '3': 34,\n",
       " '5': 35,\n",
       " '4': 36,\n",
       " '7': 37,\n",
       " '8': 38,\n",
       " '6': 39,\n",
       " 'é': 40,\n",
       " '\\x96': 41,\n",
       " '\\x85': 42,\n",
       " '´': 43,\n",
       " 'ä': 44,\n",
       " '\\x97': 45,\n",
       " 'ç': 46,\n",
       " 'ï': 47,\n",
       " 'ã': 48,\n",
       " 'è': 49,\n",
       " '“': 50,\n",
       " '”': 51,\n",
       " 'å': 52,\n",
       " 'ö': 53,\n",
       " 'à': 54,\n",
       " 'ü': 55,\n",
       " '–': 56,\n",
       " '’': 57,\n",
       " 'ó': 58,\n",
       " 'ù': 59,\n",
       " 'í': 60,\n",
       " '\\xa0': 61}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(tokenizer.texts_to_sequences(string_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n",
       "       53, 54, 55, 56, 57, 58, 59, 60, 61])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(tokenizer.texts_to_sequences(string_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ The outputs are currently letters. We first need to tokenize them, thanks to the previous dictionary.\n",
    "\n",
    "❗ **Remark** ❗ Remember that some values in `y_test` are maybe unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "y_train_tok = np.array(tokenizer.texts_to_sequences(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tok = tokenizer.texts_to_sequences(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Now, let's convert the tokenized outputs to one-hot encoded categories! There should be as many categories as different letters in the previous dictionary! So be careful that your outputs are of the right shape, especially as many one-hot encoded categories in both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "X_train[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model\n",
    "\n",
    "❓ **Question** ❓ What is the baseline accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "baseline = sorted(list(tokenizer.word_counts.values()))[-1]/sum(list(tokenizer.word_counts.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "❓ **Question** ❓ Write a RNN with all the appropriate layers, and compile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(y_train_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5600, 300), (5600, 40))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model_rnn = models.Sequential()\n",
    "\n",
    "model_rnn.add(layers.Embedding(input_dim = dico_size+1, input_length=300, output_dim=20))\n",
    "\n",
    "model_rnn.add(layers.LSTM(20))\n",
    "\n",
    "model_rnn.add(layers.Dense(50, activation = 'relu'))\n",
    "model_rnn.add(layers.Dense(25, activation = 'relu'))\n",
    "model_rnn.add(layers.Dense(40, activation = 'softmax'))\n",
    "\n",
    "model_rnn.compile(loss = \"categorical_crossentropy\",\n",
    "             optimizer = 'rmsprop',\n",
    "             metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 300, 20)           1240      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                1050      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 40)                1040      \n",
      "=================================================================\n",
      "Total params: 7,885\n",
      "Trainable params: 7,885\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 5s 65ms/step - loss: 3.2719 - accuracy: 0.1692 - val_loss: 3.0300 - val_accuracy: 0.1862\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 2.9625 - accuracy: 0.1784 - val_loss: 2.9328 - val_accuracy: 0.1862\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 2.8970 - accuracy: 0.1784 - val_loss: 2.8875 - val_accuracy: 0.1862\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 2.8486 - accuracy: 0.1784 - val_loss: 2.8532 - val_accuracy: 0.1862\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 2.7997 - accuracy: 0.1807 - val_loss: 2.7908 - val_accuracy: 0.1927\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 4s 62ms/step - loss: 2.7570 - accuracy: 0.2021 - val_loss: 2.7582 - val_accuracy: 0.2106\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 4s 62ms/step - loss: 2.7265 - accuracy: 0.2110 - val_loss: 2.7454 - val_accuracy: 0.2195\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 2.7016 - accuracy: 0.2120 - val_loss: 2.7157 - val_accuracy: 0.2177\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 2.6712 - accuracy: 0.2184 - val_loss: 2.6824 - val_accuracy: 0.2201\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 2.6311 - accuracy: 0.2378 - val_loss: 2.6495 - val_accuracy: 0.2617\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 2.5850 - accuracy: 0.2595 - val_loss: 2.6022 - val_accuracy: 0.2748\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 2.5426 - accuracy: 0.2715 - val_loss: 2.5757 - val_accuracy: 0.2683\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.5124 - accuracy: 0.2710 - val_loss: 2.5603 - val_accuracy: 0.2725\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.4899 - accuracy: 0.2756 - val_loss: 2.5369 - val_accuracy: 0.2742\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.4712 - accuracy: 0.2843 - val_loss: 2.5323 - val_accuracy: 0.2986\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.4556 - accuracy: 0.2937 - val_loss: 2.5122 - val_accuracy: 0.3046\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.4413 - accuracy: 0.2955 - val_loss: 2.5020 - val_accuracy: 0.2891\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.4300 - accuracy: 0.2950 - val_loss: 2.5001 - val_accuracy: 0.2980\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.4177 - accuracy: 0.2975 - val_loss: 2.5073 - val_accuracy: 0.2927\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 2.4093 - accuracy: 0.2960 - val_loss: 2.4840 - val_accuracy: 0.2784\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.3984 - accuracy: 0.2914 - val_loss: 2.4704 - val_accuracy: 0.2903\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 2.3894 - accuracy: 0.3006 - val_loss: 2.4629 - val_accuracy: 0.2921\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.3808 - accuracy: 0.3016 - val_loss: 2.4626 - val_accuracy: 0.2909\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 2.3715 - accuracy: 0.3019 - val_loss: 2.4526 - val_accuracy: 0.2980\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.3633 - accuracy: 0.3011 - val_loss: 2.4407 - val_accuracy: 0.2998\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.3531 - accuracy: 0.3031 - val_loss: 2.4462 - val_accuracy: 0.2885\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.3472 - accuracy: 0.3034 - val_loss: 2.4389 - val_accuracy: 0.2963\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 2.3375 - accuracy: 0.3067 - val_loss: 2.4311 - val_accuracy: 0.2968\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 2.3285 - accuracy: 0.3029 - val_loss: 2.4286 - val_accuracy: 0.2945\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.3232 - accuracy: 0.3072 - val_loss: 2.4140 - val_accuracy: 0.2927\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.3154 - accuracy: 0.3057 - val_loss: 2.4101 - val_accuracy: 0.2992\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 2.3077 - accuracy: 0.3072 - val_loss: 2.4155 - val_accuracy: 0.2980\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 2.3016 - accuracy: 0.3085 - val_loss: 2.4213 - val_accuracy: 0.2867\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 2.2941 - accuracy: 0.3118 - val_loss: 2.4057 - val_accuracy: 0.3010\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 2.2864 - accuracy: 0.3169 - val_loss: 2.3979 - val_accuracy: 0.2998\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 2.2800 - accuracy: 0.3154 - val_loss: 2.3938 - val_accuracy: 0.3076\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 2.2738 - accuracy: 0.3210 - val_loss: 2.3884 - val_accuracy: 0.3040\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.2657 - accuracy: 0.3225 - val_loss: 2.3859 - val_accuracy: 0.3052\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 2.2592 - accuracy: 0.3236 - val_loss: 2.3950 - val_accuracy: 0.2963\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.2513 - accuracy: 0.3264 - val_loss: 2.3773 - val_accuracy: 0.3129\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 2.2452 - accuracy: 0.3246 - val_loss: 2.3681 - val_accuracy: 0.3099\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 2.2386 - accuracy: 0.3292 - val_loss: 2.3690 - val_accuracy: 0.3076\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.2314 - accuracy: 0.3310 - val_loss: 2.3656 - val_accuracy: 0.3171\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.2263 - accuracy: 0.3284 - val_loss: 2.3554 - val_accuracy: 0.3177\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.2188 - accuracy: 0.3307 - val_loss: 2.3533 - val_accuracy: 0.3183\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.2111 - accuracy: 0.3287 - val_loss: 2.3576 - val_accuracy: 0.3147\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.2037 - accuracy: 0.3345 - val_loss: 2.3493 - val_accuracy: 0.3159\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.1974 - accuracy: 0.3304 - val_loss: 2.3472 - val_accuracy: 0.3206\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.1916 - accuracy: 0.3368 - val_loss: 2.3420 - val_accuracy: 0.3141\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.1849 - accuracy: 0.3371 - val_loss: 2.3419 - val_accuracy: 0.3189\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.1768 - accuracy: 0.3458 - val_loss: 2.3392 - val_accuracy: 0.3189\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.1726 - accuracy: 0.3475 - val_loss: 2.3338 - val_accuracy: 0.3206\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.1647 - accuracy: 0.3498 - val_loss: 2.3272 - val_accuracy: 0.3266\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.1601 - accuracy: 0.3450 - val_loss: 2.3244 - val_accuracy: 0.3254\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 2.1559 - accuracy: 0.3470 - val_loss: 2.3377 - val_accuracy: 0.3278\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 2.1525 - accuracy: 0.3498 - val_loss: 2.3190 - val_accuracy: 0.3296\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.1446 - accuracy: 0.3534 - val_loss: 2.3239 - val_accuracy: 0.3331\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 4s 65ms/step - loss: 2.1390 - accuracy: 0.3565 - val_loss: 2.3183 - val_accuracy: 0.3325\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.1343 - accuracy: 0.3600 - val_loss: 2.3234 - val_accuracy: 0.3224\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 2.1284 - accuracy: 0.3623 - val_loss: 2.3107 - val_accuracy: 0.3432\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.1244 - accuracy: 0.3631 - val_loss: 2.3247 - val_accuracy: 0.3319\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.1199 - accuracy: 0.3657 - val_loss: 2.3170 - val_accuracy: 0.3367\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 4s 62ms/step - loss: 2.1142 - accuracy: 0.3669 - val_loss: 2.3126 - val_accuracy: 0.3337\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 2.1094 - accuracy: 0.3674 - val_loss: 2.3280 - val_accuracy: 0.3230\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 2.1055 - accuracy: 0.3651 - val_loss: 2.3036 - val_accuracy: 0.3349\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 2.0988 - accuracy: 0.3725 - val_loss: 2.3103 - val_accuracy: 0.3409\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 2.0942 - accuracy: 0.3687 - val_loss: 2.3208 - val_accuracy: 0.3308\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.0882 - accuracy: 0.3687 - val_loss: 2.3024 - val_accuracy: 0.3355\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 2.0823 - accuracy: 0.3728 - val_loss: 2.3118 - val_accuracy: 0.3331\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.0804 - accuracy: 0.3705 - val_loss: 2.3190 - val_accuracy: 0.3409\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 2.0756 - accuracy: 0.3751 - val_loss: 2.3034 - val_accuracy: 0.3403\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.0663 - accuracy: 0.3822 - val_loss: 2.3022 - val_accuracy: 0.3432\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 2.0649 - accuracy: 0.3759 - val_loss: 2.3134 - val_accuracy: 0.3468\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.0616 - accuracy: 0.3764 - val_loss: 2.3102 - val_accuracy: 0.3403\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.0580 - accuracy: 0.3822 - val_loss: 2.3268 - val_accuracy: 0.3385\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.0497 - accuracy: 0.3802 - val_loss: 2.2998 - val_accuracy: 0.3438\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 2.0448 - accuracy: 0.3820 - val_loss: 2.3093 - val_accuracy: 0.3486\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 5s 74ms/step - loss: 2.0398 - accuracy: 0.3833 - val_loss: 2.3163 - val_accuracy: 0.3432\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.0365 - accuracy: 0.3866 - val_loss: 2.3229 - val_accuracy: 0.3409\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 2.0309 - accuracy: 0.3853 - val_loss: 2.3135 - val_accuracy: 0.3432\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 2.0276 - accuracy: 0.3876 - val_loss: 2.3121 - val_accuracy: 0.3438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x150f771c0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model_rnn.fit(X_train, y_train_cat, \n",
    "          epochs=100, \n",
    "          batch_size=64,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es],\n",
    "          workers=-1\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Fit the model - you can use a large batch size to accelerate the convergence. The model will probably hit the baseline performance at some point. If the loss gets decreasing, you will get a better accuracy then. \n",
    "\n",
    "You should get an accuracy better than 35% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_train).reshape(1400,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Evaluate your model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat = to_categorical(y_test_tok, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 10ms/step - loss: 2.2799 - accuracy: 0.3171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.279909610748291, 0.3171428442001343]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.evaluate(X_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Even though the model is not perfect, you can look at its prediction with a string of your choice. Don't forget to decoded the predicted token to know which letter it corresponds to.\n",
    "\n",
    "You will have to convert your string to a list of tokens, and then, get the most probable class and convert it back to a letter.\n",
    "\n",
    "You should do it in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Now, write a function that takes as input a string, predict the next letter, append the letter to the initial string, then redo a prediction, etc etc.\n",
    "\n",
    "For instance : \n",
    "- 'this is a good' => ' '\n",
    "- 'this is a good ' => 'm'\n",
    "- 'this is a good m' => 'o'\n",
    "...\n",
    "\n",
    "The function should take as input the number of time you repeat the operation\n",
    "\n",
    "You can have some fun trying different input sequences here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Try to optimize your architecture to improve your performance. You can also try to load more data in the first function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
