{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pGY1eTyQgGgk"
   },
   "source": [
    "## Language model\n",
    "\n",
    "In this notebook, we will build a caracter-based language model i.e. a model which given a sequence of caracters predicts the next one. We will limit the use of high-level functions, and use a simple LSTM to predict the next caracter.\n",
    "\n",
    "We will construct pairs of sentences and characters which follow, and train an LSTM to predict this next character.\n",
    "\n",
    "### This notebook should be open in a google collab environment, because it requires GPU acceleration. but it does not require external data, so you won't have to mount your drive !\n",
    "\n",
    "#### Note that, on GPU, the LSTM layer can be replaced by the CuDNNLSTM layer, which is a much faster GPU LSTM implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YMP6JdMQgGgs"
   },
   "source": [
    "## Pre-processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MumxP88_gGgy"
   },
   "source": [
    "####  The following cell reads a set of Nietzche texts and returns a string `text`, which is  the string we will use to train our language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "oOwtEaE1gGg3",
    "outputId": "2f250ed9-79ce-4699-f10f-c302cff3c38f"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "import sys\n",
    "import io\n",
    "\n",
    "path = get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "\n",
    "# removing some scarce characters\n",
    "text = text.replace('ä', 'a')\n",
    "text = text.replace('é', 'e')\n",
    "text = text.replace('ë', 'e')\n",
    "text = text.replace('_', 'e')\n",
    "text = text.replace('\\n', ' ')\n",
    "\n",
    "print('Corpus length:', len(text))\n",
    "print('Corpus extract:', text[98:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d1ohabIWg7Qc"
   },
   "source": [
    "#### Find the set of all different characters in the text. Create a sorted list `chars` with all the characters. \n",
    "(You should find 52 characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct two dictionaries:\n",
    "1. `char_to_index`. Its keys must be the characters, and its values the position of the character in the `chars` list.\n",
    "2. `index_to_char`. Its keys must be the indices in the `chars` list and the corresponding characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 937
    },
    "colab_type": "code",
    "id": "H7c9jLLBg6N4",
    "outputId": "5dddea1b-c5c2-4a91-90e6-e94be96674de"
   },
   "outputs": [],
   "source": [
    "total_chars = len(chars)\n",
    "print('total chars:', total_chars)\n",
    "char_to_index = {}\n",
    "index_to_char = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KfVTF1YWhIxj"
   },
   "source": [
    "#### Convert the 100 first characters of the text into the corresponding list of indexes and back to characters, check your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "IyW7D8tDhNju",
    "outputId": "74d2c6eb-f14b-43cb-c9d7-67e6517db704"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mpq-6AT_hst-"
   },
   "source": [
    " We will now create the data for our model. We will construct a list `sentences` which contains substrings extracted from the text, and a list `next_characters` containing the following character for each of these substrings.\n",
    "\n",
    "For simplicity, we fix the length of the sentences.\n",
    "\n",
    "Example: if the string is 'abcdefgh' and the sentence length is 3, 'abc', 'bcd', 'cde', 'def', 'efg' are possible substrings and the corresponding next characters would be 'd', 'e', 'f', 'g' and 'h'.\n",
    "\n",
    "Now if we take all possible substrings of a given length, we will build too many of them ! So we space them by step=2\n",
    "\n",
    "#### Create a list `sequences` which contains strings of length `maxlen=40` characters extracted from the `text` string, and a list `next_characters` of the characters that follow each of these strings as defined above. Consecutive strings should overlap  on `step=2` characters (i.e. if maxlen was 5 the string 'abcdefgh' should be converted into `['abcde','cdefg']` and `['f', 'h']`.) \n",
    "\n",
    "#### Print some strings and next caracters to check. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "94TKGOE-iNuR",
    "outputId": "360c9cbd-a9d9-49c9-f102-09985eb0b19c"
   },
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "step = 2\n",
    "\n",
    "sequences = []\n",
    "next_characters = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the trade-off when choosing the overlap of consecutive sentences ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if step=1 the training set is really large\n",
    "- if step is too large it is small !\n",
    "\n",
    "Note also that there is some form of leakage going on with low value for steps, since the sentences overlap. (Ideally we would use non-overlapping sentences, or at least test sentences which do not overlap with train sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GVK9ImyXjqHU"
   },
   "source": [
    "#### Now convert the sentences into an array x of shape `(len(sentences), maxlen, total_chars)` where each element of x represents the categorical representation of the sentence i.e. `x[i,j]` is the one-hot representation of the character `sequences[i,j]`. \n",
    "\n",
    "PS: you can use `to_categorical` but in this case it is dangerous, maybe implementing directly yourself this operation will work better !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7RwY9FLwk2Xi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, total_chars), dtype=np.bool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct an array y of shape `(len(sequences), total_chars)` such that y[i] is the one-hot representation of the caracter `next_characters[i]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.zeros((len(sequences), total_chars), dtype=np.bool)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why did we set `dtype=np.bool` for x and y ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not change anything about the data stored (everything is 0 and 1) but it makes the data way smaller in RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "id0Znqzsm0J4"
   },
   "source": [
    "#### Now define the model, which takes input sentences as in x and outputs the next character as in y.\n",
    "\n",
    "Your model should have an LSTM as first layer (CuDNNLSTM). What is its input shape ? How many units do you want to put ?\n",
    "\n",
    "The last layer should be a Dense layer, what is the appropriate size and activation function ?\n",
    "\n",
    "Compile your model with the appropriate loss. Use RMSProp with a learning rate of 0.001.\n",
    "\n",
    "Pro tip: aim at a model with a couple hundred thousands parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "ksnBpl4cmzYx",
    "outputId": "c7c27b60-20fb-4c8b-e04e-d379acfa1cc3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "def build_model():\n",
    "  model = Sequential()\n",
    "\n",
    "  return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEPBJBM3n6nm"
   },
   "source": [
    "#### Write a method `predict_next_char` which, given a string of len maxlen returns the next character predicted by the model. \n",
    "\n",
    "Test your method (even though the model has not been trained, just to do a first debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wRinhLSAnSd4",
    "outputId": "d648021e-4b9a-411c-cf59-d1fd8fa3f6d4"
   },
   "outputs": [],
   "source": [
    "def predict_next_char(s):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a method which, given an input string s, predicts the next 100 characters output by the model.\n",
    "Use the previous method. Test it (it should not make sense !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_language(s, n=100):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In practice, we will use the `predict_next_char` method defined below. Can you guess why ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(prediction, temperature=0.2):\n",
    "  preds = np.asarray(prediction).astype('float64')\n",
    "  preds = np.log(preds) / temperature\n",
    "  exp_preds = np.exp(preds)\n",
    "  preds = exp_preds / np.sum(exp_preds)\n",
    "  probas = np.random.multinomial(1, preds, 1)\n",
    "  return np.argmax(probas)\n",
    "\n",
    "def predict_next_char_random(s):\n",
    "    model_input = np.zeros((1, maxlen, total_chars), dtype=np.float32)\n",
    "    for j in range(maxlen):\n",
    "      model_input[0, j, char_to_index[s[j]]] = 1.\n",
    "    prediction = model.predict(model_input, verbose=0)[0]\n",
    "    next_char_index = sample(prediction)\n",
    "    next_char_index = np.argmax(prediction)\n",
    "    next_char = index_to_char[next_char_index]\n",
    "    return next_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefine the `predict_language` method using `predict_next_char_random` for the next character prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_language(s, n=100):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YZ8TYjFergMA"
   },
   "source": [
    "#### We convert this method into a callback, called at each end of epoch using this syntax, and starting from a random sentence within the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VC9dc3ahrkPi"
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "  for i in range(5):\n",
    "    pos = np.random.randint(0, len(text)-maxlen-200)\n",
    "    input_sentence = text[pos:pos+maxlen]\n",
    "    print('')\n",
    "    predict_sentence_random(input_sentence)\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YigD9wtvrTmM"
   },
   "source": [
    "#### Now fit the model for 100 epochs. Give print_callback in the list of call backs. Set `validation_split` to 0.05. Don't put any stopping criterion this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "F52Rny0inSsX",
    "outputId": "f0b99c7b-5fcf-4612-c95e-26c5bd1783cf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfitting is probably really bad above ! Add a Dropout layer after the LSTM with probability 0.5. Does it help you ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does your model generate texts which is somewhat syntaxically correct ? Does it make sense ? What directions of improvements do you see ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Language model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
