{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep Learning week - Day 3 - Exercise 2\n",
    "\n",
    "In this notebook, we propose to define a simple baseline CNN to distinguish the 10 categories from the CIFAR-10 dataset. Each image is of size (32, 32)\n",
    "\n",
    "⚠️ **Warning** ⚠️ For now, computations are done on your CPU : bear in mind that a model training will take ~10 minutes in this notebook, so don't waste your trainings !\n",
    "\n",
    "## The data\n",
    "\n",
    "❓ **Question** ❓ Load the data and the associated labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Normalize your data by dividing by the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Display some of the images using the `imshow` function from matplotlib - and print the corresponding class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# YOUR PLOT HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Convert the current labels into one-hot encoded labels - stored in `y_train` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Convolutional Neural Network\n",
    "\n",
    "Now, let's define the Convolutional Neural Network - CNN. \n",
    "\n",
    "❓ **Question** ❓ Define a CNN that is composed of:\n",
    "- a Conv2D layer with 16 filters, a kernel size of (4, 4), the relu activation function, and a padding equal to `same`\n",
    "- a MaxPooling2D layer with a pool size of (2, 2)\n",
    "- a Conv2D layer with 32 filters, a kernel size of (3, 3), the relu activation function, and a padding equal to `same`\n",
    "- a MaxPooling2D layer with a pool size of (3, 3)\n",
    "- a Conv2D layer with 64 filters, a kernel size of (3, 3), the relu activation function, and a padding equal to `same`\n",
    "- a MaxPooling2D layer with a pool size of (3, 3)\n",
    "- a Flatten layer\n",
    "- a dense function with 75 neurons with the `relu` activation function\n",
    "- a dense function related to your task\n",
    " \n",
    " PS: Do not include the compilation here.\n",
    " \n",
    " ⚠️ **Warning** ⚠️ Do not forget to add the input shape of your data to the first layer. And do not forget that it has three colors ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ What is the number of parameters of your model? \n",
    "\n",
    "Hint: `model.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Write a function to compile your model. \n",
    "\n",
    "[ Advanced ] It is not mandatory but you can try to use the `adam` optimizer with a learning rate of 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "def compile_model(model):\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Initialize a model and compile it. Then, fit it on your training data, with an early stopping (patience to 5 to keep fast computations, and the `restore_best_weights` set to True and `min_delta=1e-2` - you can check what it is in the documentation if interested).\n",
    "\n",
    "Store the output of the fit in an `history` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Run the following function on the previous history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history.history['loss'], label='train' + exp_name)\n",
    "    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n",
    "    ax1.set_ylim(0., 2.2)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n",
    "    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n",
    "    ax2.set_ylim(0.25, 1.)\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend()\n",
    "    return (ax1, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR PLOT HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Evaluate your model on the test data. Are you satisfied with these performances ? What is the chance level on this task ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "We will then introduce data augmentation: a method designed to augment the training data set by changing a bit the training images (mirroring, cropping, intensity changes, etc) while keeping the same labels. This technique is intended to improve the generalization of the model and thus improving its performance.\n",
    "\n",
    "Here, we will augment the data on the fly, at each epoch, thanks to Keras utils directly. These augmentation can be very various (see [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)), let's look at some of them. \n",
    "\n",
    "The functions might be a little confusing, but don't be disturb: it is intended to create the images on the fly instead of having them loaded into memory, which might be very heavy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.8, 1.),\n",
    "    zoom_range=(0.8, 1.2),\n",
    "    rescale=1./255.) \n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now vizualize the input data and what has been generated by the ImageDataGenerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "viz_flow = datagen.flow(X_train, shuffle=False, batch_size=1)\n",
    "\n",
    "for i, (raw_image, augmented_image) in enumerate(zip(X_train, viz_flow)):\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 2))\n",
    "    ax1.imshow(raw_image)\n",
    "    ax2.imshow(augmented_image[0])\n",
    "    plt.show()\n",
    "    \n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the model.\n",
    "\n",
    "❓ **Question** ❓ Do you estimate the estimation to be faster in terms of number of epochs ? in terms of computation time ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model\n",
    "model_2 = build_model()\n",
    "model_2 = compile_model(model_2)\n",
    "\n",
    "# The data generator\n",
    "X_tr = X_train[:30000]\n",
    "y_tr = y_train[:30000]\n",
    "X_val = X_train[30000:]\n",
    "y_val = y_train[30000:]\n",
    "train_flow = datagen.flow(X_tr, y_tr, batch_size=16)\n",
    "\n",
    "# The early stopping criterion\n",
    "es = EarlyStopping(patience=5, verbose=1, restore_best_weights=True, min_delta=1e-2)\n",
    "\n",
    "# The fit\n",
    "history_2 = model_2.fit_generator(train_flow, \n",
    "                                  epochs=100, \n",
    "                                  callbacks=[es], \n",
    "                                  validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Now, let's plot the previous and current run histories. What do you think of the data augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = plot_history(history_2, exp_name='data_augmentation')\n",
    "plot_history(history ,axs=axs, exp_name='baseline')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Evaluate the model on the test data. Do you see an improvement ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_flow = datagen.flow(X_test, y_test)\n",
    "model_2.evaluate(test_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Remark\n",
    "\n",
    "In these experiments, we stopped training quickly to have fast experiments. In practice, training must be allowed to last longer, with a a stopping criterion that has a lower delta and higher patience.\n",
    "\n",
    "Let's see how to make it quicker with the next exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
