{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIOYr2H93YDE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xp81GSFN7uHY"
   },
   "source": [
    "# Transfer learning: fine-tuning an existing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y1c4Xwno7uHm"
   },
   "source": [
    "In this notebook, we look at a way to use a pre-trained model for a different task. Namely, we will take a vgg16 neural network (https://neurohive.io/en/popular-networks/vgg16/), remove its fully connected layers, add new connected layers with the right ouput format and retrain only these layers to a classification task on flowers.\n",
    "We take vgg16 trained on Imagenet (a very large database of images of different categories), so that its filters are already trained to 'see' and extract meaningful features from the images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3kvDQa9E7uHs"
   },
   "source": [
    "#### Because the computations which follow are intensive, please open this notebook on google colab. Google colab is a free jupter environement with free GPU acceleration (up to a certain time limit). **When opening a notebook in Google Collab, change the runtime type to GPU (default is CPU-only)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "riTyl7uf3YDC"
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hB0XEe6y7uH7"
   },
   "source": [
    "#### We provide below a method `load_flowers_data` which loads the data from a google drive shared folder https://drive.google.com/open?id=10vMxWm37w8ZioysTBOnA3FSj2RqWV2Qa. Please make sure to add this shared folder to your drive. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qyji1osbf7oo"
   },
   "source": [
    "When running the next cell, you will be prompted to go into your google account and to copy/paste a validation code allowing your drive to be available from this notebook in Google Collab environment. The loading of the images may take several minutes. Note that as a first step in processing the images, we resize them all to 256x256.\n",
    "\n",
    "You might need to remount the drive sometimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BjhFM2jl3YDL"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from tqdm import tqdm\n",
    "drive.mount('/content/drive/')\n",
    "def load_flowers_data():\n",
    "    data_path = '/content/drive/My Drive/06-Deep-Learning/02/data/flowers'\n",
    "    classes = {'daisy':0, 'dandelion':1, 'rose':2}\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for (cl, i) in classes.items():\n",
    "        images_path = [elt for elt in os.listdir(os.path.join(data_path, cl)) if elt.find('.jpg')>0]\n",
    "        for img in tqdm(images_path[:300]):\n",
    "          path = os.path.join(data_path, cl, img)\n",
    "          if os.path.exists(path):\n",
    "            image = Image.open(path)\n",
    "            image = image.resize((256, 256))\n",
    "            imgs.append(np.array(image))\n",
    "            labels.append(i)\n",
    "\n",
    "    x = np.array(imgs)\n",
    "    num_classes = len(set(labels))\n",
    "    y = to_categorical(labels, num_classes)\n",
    "\n",
    "    # Finally we shuffle:\n",
    "    p = np.random.permutation(len(x))\n",
    "    x, y = x[p], y[p]\n",
    "\n",
    "    first_split = int(len(imgs) / 6.)\n",
    "    second_split = first_split + int(len(imgs) * 0.2)\n",
    "    x_test, x_val, x_train = x[:first_split], x[first_split:second_split], x[second_split:]\n",
    "    y_test, y_val, y_train = y[:first_split], y[first_split:second_split], y[second_split:]\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test, num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nlh-jOF49V9V"
   },
   "source": [
    "Use the `load_flowers_data` method and load the train, test and val images and labels as well as the number of classes. Check the dimensions of the obtained arrays. (if you encounter problems loading the files and with google drive, ask for help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mP9yFt-o3YDQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OOF7fVp27uI2"
   },
   "source": [
    "#### Plot some images, print the corresponding classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9WwloFSf3YDV"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nr6m5eKs9s54"
   },
   "source": [
    "#### Complete the methods below, which compile a model and build a model from vgg16.\n",
    "\n",
    "This should include the following steps : \n",
    "- 1) find how to make the layers of vgg16 non trainable\n",
    "- 2) declare two dense layers. The first should take as input the output of the vgg16 model (check its shape!) and the second should output a classification over 3 classes (so 3 neurons with softmax activation)\n",
    "- 3) take the input tensor, and apply vgg16 and your two layers to it. This gives you an out tensor.\n",
    "- 4) Then do model = Model(input, out) : this defines your model !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B--Gyb-23YDb"
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    opt = Adam(learning_rate=1e-4)\n",
    "    model.compile(loss=?????,\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_model():\n",
    "    vgg16_no_top = VGG16(weights=\"imagenet\", include_top=False, input_shape=x_train[0].shape)\n",
    "\n",
    "    # Set vgg16 layers to be non trainable\n",
    "\n",
    "    # Input of your model\n",
    "    inp = Input(shape=x_train[0].shape)\n",
    "    # Complete !\n",
    "    ...\n",
    "    out =  ?\n",
    "\n",
    "    model = Model(inp, out)\n",
    "    model = compile_model(model)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uNeJZvtV3YDf"
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wu2H0KZF-EoI"
   },
   "source": [
    "The VGG16 model was trained on images which were preprocessed in a specific way. Apply this processing to the images here using the method `preprocess_input` that you can import from `tensorflow.keras.applications.vgg16`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uqj2jPZI_Tz6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z97kx9yUAas5"
   },
   "source": [
    "#### Now estimate the model, with an early stopping criterion on the validation accuracy. (provide the validation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "grmnNmjeAXcQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ec_I9JpiAm-W"
   },
   "source": [
    "Plot the history of this model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESzinGOY6aBc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3plexlQAtcC"
   },
   "source": [
    "Evaluate the model accuracy on the test set. What is the chance level on this classification task (i.e. accuracy of a random classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ps_9HwUyRVj9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hjz59MOIMd3C"
   },
   "source": [
    "Find and plot some examples which were not correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AwLMuTMFMltR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vzetiM3XA2fu"
   },
   "source": [
    "#### Perform the same tasks as before but this time using data augmentation. Do you see an improvement ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-1HQzNwU3YDm"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(????) # choose your augmentation\n",
    "\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(x_train)\n",
    "\n",
    "model_data_aug = build_model()\n",
    "\n",
    "train_flow = datagen.flow(x_train, y_train, batch_size=16)\n",
    "val_flow = datagen.flow(x_val, y_val, batch_size=16)\n",
    "\n",
    "es = EarlyStopping(???)\n",
    "\n",
    "history_data_aug = model_data_aug.fit_generator(????)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RaYySOhkCiU5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IvsCub2JBre7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xs8WLByrNCLk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oF39HIb7BSOy"
   },
   "source": [
    "#### Suggest at least 4 ideas to improve the model test accuracy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7IyqGWzGBN0Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Transfer_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
