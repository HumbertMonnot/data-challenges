{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day - Airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Airflow](https://airflow.apache.org/) is a platform to programmatically author, schedule and monitor workflows. This is used beyond Machine Learning but it is very useful tool when you put Machine Learning in production.\n",
    "\n",
    "In this exercise, you will learn how to setup Airflow with GCP, create your first [DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph) and finally setup a pipeline for the Taxi Fare Prediction Challenge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ncrocfer.github.io/images/airflow-logo.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Airflow setup with GCP](#part1)\n",
    "2. [Your first DAG](#part2)\n",
    "3. [Taxi Fare Prediction Pipeline](#part3)\n",
    "4. [Data Enriching](#part4)\n",
    "5. [Real Use Case](#part5)\n",
    "6. [Your model as a product](#part6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Airflow Setup with GCP<a id=\"part1\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Cloud has a tool called `Composer` that manages Airflow for you! **Let's use that!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "- Create a [Gloud Composer]((https://console.cloud.google.com/composer) account\n",
    "- Create a new environment\n",
    "- Finally, go to Airflow Web Server interface to check it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note : Airflow uses Compute Engine resources (3 by default), it is expensive if you let it run for a week, so don't forget to delete your Airflow session at the end of the day._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Your first DAG<a id=\"part2\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write your `first_dag.py`\n",
    "- Fill in the `test()` function\n",
    "- Instantiate a `DAG` that will run every minute\n",
    "- Add an operator to the dag that calls the `test` function\n",
    "- Write a Makefile to updload this DAG to GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first_dag.py\n",
    "\n",
    "import datetime\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "\n",
    "def test():\n",
    "    \"\"\"test method\"\"\"\n",
    "    pass\n",
    "    \n",
    "\n",
    "## create DAG here\n",
    "dag = DAG()\n",
    "\n",
    "## test operator\n",
    "test_opr = PythonOperator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Taxi Fare Prediction Pipeline<a id=\"part4\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective now is to use Airflow to orchestrate and automate our TaxiFareModel pipeline. \n",
    "\n",
    "The benefit of using a \"workflows platform\" like Airflow is to breakdown our entire work into different smaller tasks. Then these tasks can run in parallel and it is easier to debug when something goes wrong and eventually you do not have to restart from scratch when a task fails.  \n",
    "\n",
    "In our TaxiFarePrediction problem, there are not a lot of steps involved, but in the future you might have to aggregate different sources of data before building a model and then apply a sequence of different steps. (we will see this in the next exercise).\n",
    "\n",
    "Also the other benefit is to schedule worlflows at specified times. For example, let's say you get new data everyday for taxi rides, so you would like to retrain a model every day with this new data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exericise\n",
    "\n",
    "For now, we just want you to know how to automatically submit new trainings for you model to GCP, using Airflow.\n",
    "The idea is to send a new training once every hour for example.\n",
    "\n",
    "- Write a DAG `dag_training_job.py` that will send a new training to GCP for the TaxiFareModel once every x minutes.\n",
    "- Use a `Makefile` to build and updload dependencies and submit your DAG to GCP.\n",
    "\n",
    "TIP: You will have to use [MLEngineTrainingOperator](https://airflow.apache.org/docs/stable/_api/airflow/contrib/operators/mlengine_operator/index.html#airflow.contrib.operators.mlengine_operator.MLEngineTrainingOperator)\n",
    "\n",
    "Check that you see new training tasks and new models on your AI Platform Console.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Enriching<a id=\"part5\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to make things more interesting and leverage the power of Airflow, let's enrich our data with weather data!\n",
    "It makes sense to think that weather may influence traffic in NYC, hence taxi riding times and fares. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective here is to run a worklow gathering data from external source and save this data into Google Big Query\n",
    "\n",
    "#### Weather API\n",
    "Create a free account on this [Weather API](https://www.worldweatheronline.com/developer/api/docs/historical-weather-api.aspx#qparameter). No card needed for account creation\n",
    "\n",
    "- Get your ApiKey\n",
    "- Implement `WeatherApi()` class inside `data_enriching.py` aiming at connecting to the API, and getting current day's weather data (only one point)\n",
    "- Now implement load_bq_table_from_df() to load api result into a new BQ table named `weather_data`\n",
    "- Test your 2 functions by requesting data from 2018 and inserting it into our table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data_enriching.py\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from datetime import date\n",
    "\n",
    "ApiKey = \"<your_api_key>\"\n",
    "\n",
    "\n",
    "class weather_api(object):\n",
    "    \n",
    "    def __init__(self, api_key=ApiKey):\n",
    "        self.url = 'http://api.worldweatheronline.com/premium/v1/past-weather.ashx'\n",
    "        self.apikey = api_key\n",
    "\n",
    "    def get_day_data(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def load_bq_table_from_df(df, dataset, table):\n",
    "    pass\n",
    "\n",
    "\n",
    "def run():\n",
    "    \"\"\"test enriching data into BigQuery \"\"\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have weather data collected. Modify your training task to:\n",
    "- Query weather data and merge it with the historical rides data\n",
    "- Build one or more weather features and add then into your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Real Use Case - Putting all together<a id=\"part5\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put all things together!\n",
    "Imagine you want a model that gets retrained everyday using new data (weather + historical rides).\n",
    "\n",
    "Now let us take a step back and check what we've done so far. We have implemented:\n",
    "\n",
    "- A DAG that launches, on GCP, model training jobs.\n",
    "- A DAG that gathers weather data every day and store it inside a BQ Table.\n",
    "\n",
    "Additionally, let us imagine that we have every day, fresh new raw data uploaded every night into a Storage Bucket, with the rides of the day.\n",
    "\n",
    "We might want to \n",
    "1. Enrich our training data with the daily gathered data, both raw and weather data\n",
    "2. Launch a daily training on enriched training data \n",
    "3. Use every day our newly trained model to predict price of a new ride (note: in a real situation, you might also need to collect weather predictions when making fares estimations).\n",
    "\n",
    "#### Implementation\n",
    "\n",
    "Implement a DAG that will, at 12:30 am every day:\n",
    "\n",
    "- collect new weather data\n",
    "- merge weather data with rides data (you can create a new Big Query Table `taxi_rides` table for example)\n",
    "- launch a new training task with the most recent data\n",
    "- create a new version of the model \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Your model as a product<a id=\"part6\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this last exercise, the goal is to make your model publicly available and visible. The idea is build a http endpoint that can be used by anyone to request a fare estimation.\n",
    "\n",
    "At the end of this exercise, you should have a web app where people can request a taxi fare estimate in NYC by inputing their pickup and destination (similar to what Uber provides [here](https://www.uber.com/fr/fr/price-estimate/).\n",
    "\n",
    "For this, you are going to build a [Flask](https://flask.palletsprojects.com/en/1.1.x/quickstart/) application (for those who followed the Web Bootcamp, this is equivalent of [Sinatra](http://sinatrarb.com/) on Ruby, but with Python)\n",
    "This Webapp will be deployed using [Google App Engine](https://cloud.google.com/appengine/docs/standard/python3/building-app/?hl=fr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read the [Flask quickstart](https://flask.palletsprojects.com/en/1.1.x/quickstart/) to see how you can run a simple Flask application locally\n",
    "- Build a simple route that will call your TaxFarePrediction model given the location parameters and passenger count. You may want to assume the fare estimation is requested for a ride that happens now.\n",
    "- Deploy the app with Google App Engine\n",
    "- If you want to go further, you can also build a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
