{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3 - ML Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have already built a simple, we want to make it better! The ultimate goal is having a model that makes more accurate predictions on the test set, hence getting a RMSE as low as possible.\n",
    "\n",
    "**So what can we do?**\n",
    "\n",
    "There are many different things that make models better:\n",
    "- build and try to use different or more features\n",
    "- test with different estimators (linear, non linear, etc..)\n",
    "- tune hyperparameters\n",
    "\n",
    "\n",
    "The problem is that it is often hard to keep track of this different experimentations. There are many different parameters that we can tune and many different combinations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[MLFlow](https://www.mlflow.org/docs/latest/concepts.html) is a very useful tool to help us in machine learning models iteration.** \n",
    "\n",
    "In this series of exercise, you will get hands on using the [MLFlow Tracking Api](https://www.mlflow.org/docs/latest/tracking.html) in order to experiment with different features, models and parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "0. [Workflow setup](#part0)\n",
    "1. [Setup MLflow Tracking](#part1)\n",
    "2. [Try different models](#part2)\n",
    "3. [Features engineering](#part3)\n",
    "4. [Hyperparameters tuning](#part4)\n",
    "5. [MLFlow Projects](#part5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Workflow Setup <a id=\"part0\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to move away from Jupyter Notebook, and start writing reusable code with python modules and classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create our folder structure:\n",
    "\n",
    "1. Create a folder with the name of your project/module, for example `TaxiFareModel`\n",
    "2. Inside this folder, create a `__init_.py` file to make it a python module\n",
    "3. Then create multiple python files that will contain the different python classes or methods we need\n",
    "\n",
    "\n",
    "* `trainer.py`: **Trainer** class that will be our main class that trains our model\n",
    "* `data.py`: **Data** class that will be responsible for getting the input raw data\n",
    "* `utils.py`: any utility functions you may have\n",
    "* `encoders.py`: your custom encoders and transformers\n",
    "\n",
    "You should have something like:\n",
    "\n",
    "* TaxiFareModel\n",
    "    * __init__.py\n",
    "    * trainer.py\n",
    "    * data.py\n",
    "    * utils.py\n",
    "    * encoders.py\n",
    "    * data\n",
    "      * train.csv\n",
    "      * test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data.py\n",
    "- Create the `Data` class. This class should have a method `get_data` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    \n",
    "    def get_data(self, nrows=None, test=False):\n",
    "        \"\"\"returns the input data\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utils.py\n",
    "- In `utils.py` this where you can have :\n",
    " - `haversine_distance` method\n",
    " - `compute_rmse` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### encoders.py\n",
    "- In `encoders.py` let's put the custom encoders and transformers you have for distance and time features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trainer.py\n",
    "- The `Trainer` class is the main class. It should have:\n",
    "  - a `def get_estimator()` to return the estimator chosent to train the model\n",
    "  - a `def get_pipeline()` method that builds the pipeline\n",
    "  - a `def fit()` method that train the pipeline\n",
    "  \n",
    "  \n",
    "- You can also have a `train` method that:\n",
    " - gets the training data\n",
    " - split date into train/validation sets\n",
    " - fits a model on that training data\n",
    " - evaludate the model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pipeline = None\n",
    "    \n",
    "    def get_estimator(self):\n",
    "        \"\"\"return estimator\"\"\"\n",
    "            \n",
    "    def get_pipeline(self):\n",
    "        \"\"\"returns pipeline \"\"\"\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        \"\"\"fits the entire pipeline with df_train\"\"\"\n",
    "        pipeline = self.get_pipeline()\n",
    "        # code to fit the pipeline\n",
    "        self.pipeline = pipeline\n",
    "        \n",
    "    def evaluate(self, df_test):\n",
    "        \"\"\"evaluates the pipeline on df_test\"\"\"\n",
    "    \n",
    "    def train(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it!\n",
    "- Once you have everything setup, test that it works by calling `Trainer.train()` from your notebook.\n",
    "- Do not hesitate to only breakdown your code into smaller calls for debugging\n",
    "- Tip\n",
    "  - add `%load_ext autoreload` and `%autoreload 2` in your notebook to automaticall have new code imported anytime you make a change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from TaxiFareModel.trainer import Trainer\n",
    "# t = Trainer()\n",
    "# t.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup MLFlow Tracking <a id=\"part1\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since that now we have a good workflow to make model improvements, it is very important to track all our different experiments. We want to be able to save all our differents training runs and compare their performance.\n",
    "\n",
    "This is what MLFlow tracking is about.\n",
    "\n",
    "#### Exercise\n",
    "- Read [MLFlow Quickstart](https://www.mlflow.org/docs/latest/quickstart.html#quickstart)\n",
    "- Install MLFlow with `pip install mlflow`\n",
    "- Setup MLFlow in your code to start logging training runs\n",
    " - Think about which parameters you want to log\n",
    " - Think about the metric you want to log\n",
    "- Re-organize your code in order to easily log the different parameters and metrics you need\n",
    "    - Extract out the different parameters you may have in your code and make them inputs of your `Trainer(object)` class.\n",
    "    - **Tips**:\n",
    "       - If you want to log the estimator used, you can do it with `estimator.__class__.__name__`\n",
    "       - Look at the estimator documentation to extract the params programmatically \n",
    "    - Write a method `log_mlflow_params` to automatically log the params\n",
    "- View results with `mlflow ui`\n",
    "\n",
    "To go further, look at the [full doc](https://www.mlflow.org/docs/latest/tracking.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def get_estimator(self):\n",
    "        \"\"\"use kwargs to set your estimator and params \"\"\"\n",
    "        \n",
    "    def log_mlflow_params(self, **kwargs):\n",
    "        \"\"\"log params to mlflow here\"\"\"\n",
    "        \n",
    "    def log_mlflow_metric(self, **kwargs):\n",
    "        \"\"\"log metric to mlflow here\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organize your runs into MLflow Experiments\n",
    "In order to have your runs organized, you can leverage [MLFlow experiments](https://www.mlflow.org/docs/latest/tracking.html#organizing-runs-in-experiments).\n",
    "\n",
    "For this, it is easier to use the MLFlow API with [`MlflowClient`](https://www.mlflow.org/docs/latest/python_api/mlflow.tracking.html#module-mlflow.tracking)\n",
    "\n",
    "#### Exercise\n",
    "- Write a few additional methods to manage the creation of experiments and runs in your class.\n",
    "- Also write wrappers around `log_metric` and `log_param` MLflow methods to easily log based on your current experiment and run\n",
    "- @memoized_property is a useful decorator to declare properties see [https://pypi.org/project/memoized-property/](https://pypi.org/project/memoized-property/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TaxiFareModel.trainer import Trainer\n",
    "t = Trainer(experiment_name='Experiment0')\n",
    "t.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write a loop that will launch multiple runs for different parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TaxiFareModel.trainer import Trainer\n",
    "for param in ['param1', 'param2', 'param3']:\n",
    "    t = Trainer(experiment_name='Experiment1', param=param)\n",
    "    t.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then go to MLFlow UI to see the different runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Try different models <a id=\"part2\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a way to track different iterations, it is time to experiment!\n",
    "\n",
    "**First, let's try different estimators.**\n",
    "\n",
    "#### Exercise\n",
    "- Think about the different estimators that you know that can be used to solve prediction problems\n",
    "- Implement a short script that will loop through all estimators, train the model and evalulate it on a validation set.\n",
    "- Be careful: make sure you always use the same validation set accross all your trainings. **Tip** you can set the random seed for `train_test_split` to make sure the split is always the same.\n",
    "- Compare performance with `mlflow ui`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Features engineering and selection <a id=\"part3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now it is time to be creative!**\n",
    "\n",
    "You just tried different models, and you now see that some estimators may be more powerful than others. Another area where you can experiment is about `features engineering`. \n",
    "\n",
    "#### Exercise 1\n",
    "- Try different combinations of features (by removing or adding some) and track the runs.\n",
    "- Use [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) transfomer to generate new features from distance.\n",
    "- Compute other types of distance (straightline, manhattan, travel, etc..)\n",
    "- Use some \"context knowledge\" to generate new features that you think might be relevant.\n",
    " - For example: we know that taxis apply a fixed fare for airport transfers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 2\n",
    "- Try different methods for outliers removals\n",
    "- Look at how the size of the training set helps reduce the RMSE on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hyperparameters tuning <a id=\"part4\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, once you are satisfied with your features engineering work, **let's fine tune your model.**\n",
    "\n",
    "For this, we recommand you choosing a `Gradient Boosting Tree` estimator ([Xgboost](https://xgboost.readthedocs.io/en/latest/get_started.html) or [LightGBM](https://lightgbm.readthedocs.io/en/latest/) or [GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)).\n",
    "\n",
    "The idea is to tune the hyperparameters of this estimator. The most important parameters to tune are:\n",
    "- `learning_rate`\n",
    "- `max_depth`\n",
    "- `n_estimators`\n",
    "\n",
    "To perform hyperparameters search, you have the choice between two `search` mechanisms:\n",
    "- [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "- [RandomSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "\n",
    "\n",
    "#### Exercise\n",
    "- First, try to adjust the hyperparameters manually and do a few runs that you can track with MLFlow. Then [with MLFlow UI you can visually see how these parameters affect the performance metric](https://mlflow.org/docs/latest/tracking.html#visualizing-metrics).\n",
    "- Once you have an idea of how the parameters impact RMSE, try to implement both `GridSearch` and `RandomSearch` as part of your pipeline to fully tune the model.\n",
    "- Once you are satisfied with your tuned model, submit your predictions to Kaggle!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. MLFlow projects <a id=\"part5\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To go further, look at [MLFlow Projects](https://www.mlflow.org/docs/latest/projects.html#) and see how you can use them to perform hyperparameters tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
